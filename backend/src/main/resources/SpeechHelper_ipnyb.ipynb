{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechHelper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXbkJSUMGVTZ",
        "outputId": "8ffbe971-2f1d-4728-fd13-8f7664330d6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjdbDugARDG-",
        "outputId": "17055ca3-5553-4ffd-a420-2f899c5da5a2"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXe3XpTiRdhF"
      },
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "\n",
        "data, sampling_rate = librosa.load('/content/drive/My Drive/Audio_Speech_Actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "yKgWOlCPSIva",
        "outputId": "33974c6e-27c2-4f80-b45d-74afc7ad769d"
      },
      "source": [
        "\n",
        "% pylab inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PolyCollection at 0x7f7536369bd0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw4OX6iti0jK"
      },
      "source": [
        "Feature extraction using d tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUJetfVvSUWP"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from librosa import display\n",
        "\n",
        "#path = '/content/drive/My Drive/Audio_Speech_Actors_01-24/Actor_01/'\n",
        "#path = '/content/drive/My Drive/Speech/AudioFiles/Actor_01/'\n",
        "path = '/content/drive/My Drive/Speech/'\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        #print(file)\n",
        "        arr = mfccs, file\n",
        "        #print(arr)\n",
        "        lst.append(arr)\n",
        "        #print(lst)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6oj8WiBs1W8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuCEX7YASp-J"
      },
      "source": [
        "\n",
        "X, y = zip(*lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlPNxlyFSuM5",
        "outputId": "9efde272-89bf-4f85-ce41-28e50939a4ac"
      },
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1440, 40), (1440,))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxOjz68jSyLh"
      },
      "source": [
        "import joblib\n",
        "\n",
        "X_name = 'X.joblib'\n",
        "y_name = 'y.joblib'\n",
        "save_dir = '/content/drive/My Drive/Model/'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or9NqPPUYyii"
      },
      "source": [
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/Model/X.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/Model/y.joblib')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-qX1qyJZdTa"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af-3cJJuZhSn"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ASTEhcssZkY3",
        "outputId": "f7583d55-013c-4e67-b26a-9e61e0abbd45"
      },
      "source": [
        "dtree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                       random_state=None, splitter='best')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-804be5c9bba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        random_state=None, splitter='best')\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_impurity_split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwgjI_R8aDuQ",
        "outputId": "d7fab2ec-16ad-4bcf-9c77-d0facc3d074a"
      },
      "source": [
        "dtree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='random')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keg-cezJaHLC"
      },
      "source": [
        "predictions = dtree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9tYrhyD0RbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "gqlD0hU2aKoa",
        "outputId": "886ed363-c015-44bd-a820-3c7a9b0361c4"
      },
      "source": [
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a950aae27142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGtgxs6wi8GZ"
      },
      "source": [
        "Feature extraction using Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5A5SxxUaa_x"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK1hp0CcaeC0"
      },
      "source": [
        "# gini criterion\n",
        "rforest = RandomForestClassifier(criterion=\"entropy\", max_depth=10, max_features=\"log2\", \n",
        "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 10, \n",
        "                                 n_estimators= 22000, random_state= 40)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHXOsXYhahVM",
        "outputId": "6ef9353e-d8e3-4cf0-d48b-f31179867680"
      },
      "source": [
        "rforest.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', max_depth=10, max_features='log2',\n",
              "                       max_leaf_nodes=100, min_samples_leaf=3,\n",
              "                       min_samples_split=10, n_estimators=22000,\n",
              "                       random_state=40)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i23UgW-0Tx8"
      },
      "source": [
        "predictions = rforest.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qO4exJ1bAQf",
        "outputId": "cf9df18b-ba0a-499e-b328-63d73b12da89"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86        90\n",
            "           1       0.44      0.76      0.55        45\n",
            "           2       0.99      0.65      0.79       130\n",
            "           3       0.78      0.68      0.73       111\n",
            "           4       0.88      0.83      0.86       111\n",
            "           5       0.84      0.79      0.81       130\n",
            "           6       0.59      0.88      0.71       110\n",
            "           7       0.76      0.79      0.78       121\n",
            "\n",
            "    accuracy                           0.77       848\n",
            "   macro avg       0.78      0.77      0.76       848\n",
            "weighted avg       0.81      0.77      0.78       848\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUnVCJ0Js2lM"
      },
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4BTRh40tBCa",
        "outputId": "96e0fd7c-1594-40a8-b5f4-cab82863b5ae"
      },
      "source": [
        "x_traincnn.shape, x_testcnn.shape\n",
        "#print(X_train.shape[1], X_train.shape[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3392, 40, 1), (848, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZx9A2tltBqg",
        "outputId": "7a4a9001-ab4a-42fc-8640-f86e2129c5e6"
      },
      "source": [
        "!pip install keras\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128, 5,padding='same',\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same', input_shape=(40,1)))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "model.add(Conv1D(128, 5,padding='same', input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXfD9CFrucmq",
        "outputId": "f0caff1a-d6e1-4e43-d0ed-4b6627e8b146"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           768       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 5, 128)            82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1, 128)            82048     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1, 128)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 1032      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165,896\n",
            "Trainable params: 165,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Sft-xzukUV"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDJV0Ru6uoft",
        "outputId": "2f56f60a-da7f-4cc4-bc03-f825eacfa1ef"
      },
      "source": [
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1300, validation_data=(x_testcnn, y_test))\n",
        "#History = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=1150, epochs=30)\n",
        "\n",
        "#cnnhistory=model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=16) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1300\n",
            "212/212 [==============================] - 3s 9ms/step - loss: 3.1174 - accuracy: 0.2011 - val_loss: 1.7057 - val_accuracy: 0.3833\n",
            "Epoch 2/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.8637 - accuracy: 0.3641 - val_loss: 1.4814 - val_accuracy: 0.5024\n",
            "Epoch 3/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.5315 - accuracy: 0.4522 - val_loss: 1.3063 - val_accuracy: 0.5719\n",
            "Epoch 4/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.3874 - accuracy: 0.5077 - val_loss: 1.3118 - val_accuracy: 0.5425\n",
            "Epoch 5/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.2688 - accuracy: 0.5563 - val_loss: 1.1810 - val_accuracy: 0.5825\n",
            "Epoch 6/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 1.1934 - accuracy: 0.5746 - val_loss: 1.0854 - val_accuracy: 0.6132\n",
            "Epoch 7/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.1081 - accuracy: 0.6100 - val_loss: 1.0328 - val_accuracy: 0.6403\n",
            "Epoch 8/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 1.0343 - accuracy: 0.6347 - val_loss: 0.9790 - val_accuracy: 0.6816\n",
            "Epoch 9/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 1.0041 - accuracy: 0.6551 - val_loss: 0.9543 - val_accuracy: 0.6580\n",
            "Epoch 10/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.9463 - accuracy: 0.6757 - val_loss: 0.9306 - val_accuracy: 0.6816\n",
            "Epoch 11/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.9184 - accuracy: 0.6766 - val_loss: 0.9072 - val_accuracy: 0.6769\n",
            "Epoch 12/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.8840 - accuracy: 0.6878 - val_loss: 0.8826 - val_accuracy: 0.6993\n",
            "Epoch 13/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.8568 - accuracy: 0.6940 - val_loss: 0.8608 - val_accuracy: 0.7052\n",
            "Epoch 14/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.8289 - accuracy: 0.7049 - val_loss: 0.8524 - val_accuracy: 0.6993\n",
            "Epoch 15/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.8114 - accuracy: 0.7058 - val_loss: 0.8369 - val_accuracy: 0.7005\n",
            "Epoch 16/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.7883 - accuracy: 0.7193 - val_loss: 0.8042 - val_accuracy: 0.7193\n",
            "Epoch 17/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.7730 - accuracy: 0.7140 - val_loss: 0.8034 - val_accuracy: 0.7111\n",
            "Epoch 18/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.7548 - accuracy: 0.7267 - val_loss: 0.7891 - val_accuracy: 0.7123\n",
            "Epoch 19/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.7522 - accuracy: 0.7223 - val_loss: 0.7860 - val_accuracy: 0.6993\n",
            "Epoch 20/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.7381 - accuracy: 0.7161 - val_loss: 0.7835 - val_accuracy: 0.7193\n",
            "Epoch 21/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.7372 - accuracy: 0.7279 - val_loss: 0.7744 - val_accuracy: 0.7134\n",
            "Epoch 22/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.7208 - accuracy: 0.7264 - val_loss: 0.7609 - val_accuracy: 0.7205\n",
            "Epoch 23/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.7094 - accuracy: 0.7388 - val_loss: 0.7614 - val_accuracy: 0.7146\n",
            "Epoch 24/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6978 - accuracy: 0.7376 - val_loss: 0.7444 - val_accuracy: 0.7241\n",
            "Epoch 25/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6950 - accuracy: 0.7391 - val_loss: 0.7394 - val_accuracy: 0.7311\n",
            "Epoch 26/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6864 - accuracy: 0.7403 - val_loss: 0.7599 - val_accuracy: 0.7241\n",
            "Epoch 27/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6801 - accuracy: 0.7473 - val_loss: 0.7375 - val_accuracy: 0.7205\n",
            "Epoch 28/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6772 - accuracy: 0.7500 - val_loss: 0.7309 - val_accuracy: 0.7276\n",
            "Epoch 29/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6744 - accuracy: 0.7473 - val_loss: 0.7235 - val_accuracy: 0.7417\n",
            "Epoch 30/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6700 - accuracy: 0.7453 - val_loss: 0.7402 - val_accuracy: 0.7217\n",
            "Epoch 31/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6599 - accuracy: 0.7535 - val_loss: 0.7151 - val_accuracy: 0.7241\n",
            "Epoch 32/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6646 - accuracy: 0.7488 - val_loss: 0.7071 - val_accuracy: 0.7406\n",
            "Epoch 33/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6528 - accuracy: 0.7532 - val_loss: 0.7067 - val_accuracy: 0.7441\n",
            "Epoch 34/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6429 - accuracy: 0.7568 - val_loss: 0.6999 - val_accuracy: 0.7382\n",
            "Epoch 35/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6417 - accuracy: 0.7556 - val_loss: 0.6890 - val_accuracy: 0.7358\n",
            "Epoch 36/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6373 - accuracy: 0.7612 - val_loss: 0.6902 - val_accuracy: 0.7429\n",
            "Epoch 37/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6379 - accuracy: 0.7591 - val_loss: 0.6947 - val_accuracy: 0.7547\n",
            "Epoch 38/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6245 - accuracy: 0.7680 - val_loss: 0.6845 - val_accuracy: 0.7453\n",
            "Epoch 39/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6295 - accuracy: 0.7588 - val_loss: 0.6931 - val_accuracy: 0.7488\n",
            "Epoch 40/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6271 - accuracy: 0.7642 - val_loss: 0.6793 - val_accuracy: 0.7441\n",
            "Epoch 41/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6180 - accuracy: 0.7662 - val_loss: 0.6833 - val_accuracy: 0.7500\n",
            "Epoch 42/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6154 - accuracy: 0.7689 - val_loss: 0.6807 - val_accuracy: 0.7524\n",
            "Epoch 43/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6168 - accuracy: 0.7659 - val_loss: 0.6726 - val_accuracy: 0.7453\n",
            "Epoch 44/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6023 - accuracy: 0.7721 - val_loss: 0.6859 - val_accuracy: 0.7311\n",
            "Epoch 45/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6056 - accuracy: 0.7680 - val_loss: 0.6575 - val_accuracy: 0.7465\n",
            "Epoch 46/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.6022 - accuracy: 0.7677 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
            "Epoch 47/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5945 - accuracy: 0.7774 - val_loss: 0.6610 - val_accuracy: 0.7689\n",
            "Epoch 48/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5964 - accuracy: 0.7745 - val_loss: 0.6604 - val_accuracy: 0.7500\n",
            "Epoch 49/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5884 - accuracy: 0.7762 - val_loss: 0.6702 - val_accuracy: 0.7535\n",
            "Epoch 50/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5987 - accuracy: 0.7709 - val_loss: 0.6516 - val_accuracy: 0.7642\n",
            "Epoch 51/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5915 - accuracy: 0.7789 - val_loss: 0.6485 - val_accuracy: 0.7559\n",
            "Epoch 52/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5944 - accuracy: 0.7706 - val_loss: 0.6512 - val_accuracy: 0.7559\n",
            "Epoch 53/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5850 - accuracy: 0.7839 - val_loss: 0.6652 - val_accuracy: 0.7524\n",
            "Epoch 54/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5778 - accuracy: 0.7812 - val_loss: 0.6571 - val_accuracy: 0.7583\n",
            "Epoch 55/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5761 - accuracy: 0.7895 - val_loss: 0.6452 - val_accuracy: 0.7559\n",
            "Epoch 56/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5762 - accuracy: 0.7866 - val_loss: 0.6374 - val_accuracy: 0.7594\n",
            "Epoch 57/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5700 - accuracy: 0.7874 - val_loss: 0.6404 - val_accuracy: 0.7724\n",
            "Epoch 58/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5741 - accuracy: 0.7833 - val_loss: 0.6495 - val_accuracy: 0.7535\n",
            "Epoch 59/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5595 - accuracy: 0.7916 - val_loss: 0.6632 - val_accuracy: 0.7559\n",
            "Epoch 60/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5683 - accuracy: 0.7874 - val_loss: 0.6450 - val_accuracy: 0.7618\n",
            "Epoch 61/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5685 - accuracy: 0.7833 - val_loss: 0.6457 - val_accuracy: 0.7594\n",
            "Epoch 62/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5597 - accuracy: 0.7913 - val_loss: 0.6327 - val_accuracy: 0.7665\n",
            "Epoch 63/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5576 - accuracy: 0.7913 - val_loss: 0.6321 - val_accuracy: 0.7571\n",
            "Epoch 64/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5556 - accuracy: 0.7936 - val_loss: 0.6366 - val_accuracy: 0.7618\n",
            "Epoch 65/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5613 - accuracy: 0.7930 - val_loss: 0.6593 - val_accuracy: 0.7524\n",
            "Epoch 66/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5565 - accuracy: 0.7972 - val_loss: 0.6261 - val_accuracy: 0.7535\n",
            "Epoch 67/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5487 - accuracy: 0.7995 - val_loss: 0.6191 - val_accuracy: 0.7630\n",
            "Epoch 68/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5419 - accuracy: 0.7922 - val_loss: 0.6392 - val_accuracy: 0.7559\n",
            "Epoch 69/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5495 - accuracy: 0.7925 - val_loss: 0.6248 - val_accuracy: 0.7524\n",
            "Epoch 70/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5389 - accuracy: 0.7983 - val_loss: 0.6184 - val_accuracy: 0.7571\n",
            "Epoch 71/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5421 - accuracy: 0.7954 - val_loss: 0.6213 - val_accuracy: 0.7653\n",
            "Epoch 72/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5357 - accuracy: 0.7978 - val_loss: 0.6395 - val_accuracy: 0.7700\n",
            "Epoch 73/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5306 - accuracy: 0.8040 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
            "Epoch 74/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5385 - accuracy: 0.7948 - val_loss: 0.6228 - val_accuracy: 0.7700\n",
            "Epoch 75/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5314 - accuracy: 0.7978 - val_loss: 0.6169 - val_accuracy: 0.7700\n",
            "Epoch 76/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5242 - accuracy: 0.8025 - val_loss: 0.6099 - val_accuracy: 0.7665\n",
            "Epoch 77/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5189 - accuracy: 0.8045 - val_loss: 0.6103 - val_accuracy: 0.7606\n",
            "Epoch 78/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5260 - accuracy: 0.8013 - val_loss: 0.6143 - val_accuracy: 0.7547\n",
            "Epoch 79/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5225 - accuracy: 0.8060 - val_loss: 0.6146 - val_accuracy: 0.7700\n",
            "Epoch 80/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5201 - accuracy: 0.8119 - val_loss: 0.6360 - val_accuracy: 0.7594\n",
            "Epoch 81/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5151 - accuracy: 0.8084 - val_loss: 0.6050 - val_accuracy: 0.7618\n",
            "Epoch 82/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5161 - accuracy: 0.8098 - val_loss: 0.6135 - val_accuracy: 0.7594\n",
            "Epoch 83/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5178 - accuracy: 0.8110 - val_loss: 0.6046 - val_accuracy: 0.7618\n",
            "Epoch 84/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5117 - accuracy: 0.8054 - val_loss: 0.6017 - val_accuracy: 0.7700\n",
            "Epoch 85/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5061 - accuracy: 0.8081 - val_loss: 0.6019 - val_accuracy: 0.7854\n",
            "Epoch 86/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5101 - accuracy: 0.8143 - val_loss: 0.5992 - val_accuracy: 0.7689\n",
            "Epoch 87/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5079 - accuracy: 0.8154 - val_loss: 0.5920 - val_accuracy: 0.7736\n",
            "Epoch 88/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5061 - accuracy: 0.8131 - val_loss: 0.5985 - val_accuracy: 0.7712\n",
            "Epoch 89/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5023 - accuracy: 0.8087 - val_loss: 0.5946 - val_accuracy: 0.7677\n",
            "Epoch 90/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.5006 - accuracy: 0.8143 - val_loss: 0.5900 - val_accuracy: 0.7795\n",
            "Epoch 91/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4972 - accuracy: 0.8134 - val_loss: 0.6020 - val_accuracy: 0.7759\n",
            "Epoch 92/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4941 - accuracy: 0.8199 - val_loss: 0.6057 - val_accuracy: 0.7677\n",
            "Epoch 93/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.4948 - accuracy: 0.8193 - val_loss: 0.6039 - val_accuracy: 0.7665\n",
            "Epoch 94/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4916 - accuracy: 0.8178 - val_loss: 0.5916 - val_accuracy: 0.7712\n",
            "Epoch 95/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4913 - accuracy: 0.8152 - val_loss: 0.6112 - val_accuracy: 0.7712\n",
            "Epoch 96/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4882 - accuracy: 0.8210 - val_loss: 0.5784 - val_accuracy: 0.7807\n",
            "Epoch 97/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4808 - accuracy: 0.8252 - val_loss: 0.5892 - val_accuracy: 0.7783\n",
            "Epoch 98/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4814 - accuracy: 0.8193 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
            "Epoch 99/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4831 - accuracy: 0.8190 - val_loss: 0.5889 - val_accuracy: 0.7700\n",
            "Epoch 100/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4811 - accuracy: 0.8210 - val_loss: 0.5903 - val_accuracy: 0.7783\n",
            "Epoch 101/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4811 - accuracy: 0.8190 - val_loss: 0.5801 - val_accuracy: 0.7677\n",
            "Epoch 102/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4785 - accuracy: 0.8222 - val_loss: 0.5979 - val_accuracy: 0.7830\n",
            "Epoch 103/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4838 - accuracy: 0.8228 - val_loss: 0.6101 - val_accuracy: 0.7700\n",
            "Epoch 104/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4772 - accuracy: 0.8172 - val_loss: 0.5828 - val_accuracy: 0.7689\n",
            "Epoch 105/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4782 - accuracy: 0.8243 - val_loss: 0.5877 - val_accuracy: 0.7736\n",
            "Epoch 106/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4803 - accuracy: 0.8267 - val_loss: 0.5817 - val_accuracy: 0.7724\n",
            "Epoch 107/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4740 - accuracy: 0.8222 - val_loss: 0.5733 - val_accuracy: 0.7830\n",
            "Epoch 108/1300\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.4687 - accuracy: 0.8331 - val_loss: 0.5832 - val_accuracy: 0.7854\n",
            "Epoch 109/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.8213 - val_loss: 0.5930 - val_accuracy: 0.7783\n",
            "Epoch 110/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4584 - accuracy: 0.8290 - val_loss: 0.5778 - val_accuracy: 0.7854\n",
            "Epoch 111/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4609 - accuracy: 0.8269 - val_loss: 0.5944 - val_accuracy: 0.7866\n",
            "Epoch 112/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4560 - accuracy: 0.8246 - val_loss: 0.5984 - val_accuracy: 0.7771\n",
            "Epoch 113/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4606 - accuracy: 0.8231 - val_loss: 0.5791 - val_accuracy: 0.7771\n",
            "Epoch 114/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4564 - accuracy: 0.8272 - val_loss: 0.6028 - val_accuracy: 0.7642\n",
            "Epoch 115/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4593 - accuracy: 0.8296 - val_loss: 0.5778 - val_accuracy: 0.7700\n",
            "Epoch 116/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4534 - accuracy: 0.8349 - val_loss: 0.5749 - val_accuracy: 0.7983\n",
            "Epoch 117/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4522 - accuracy: 0.8367 - val_loss: 0.5969 - val_accuracy: 0.7606\n",
            "Epoch 118/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4551 - accuracy: 0.8323 - val_loss: 0.5837 - val_accuracy: 0.7795\n",
            "Epoch 119/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4526 - accuracy: 0.8364 - val_loss: 0.5702 - val_accuracy: 0.7866\n",
            "Epoch 120/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4502 - accuracy: 0.8373 - val_loss: 0.5699 - val_accuracy: 0.7889\n",
            "Epoch 121/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4479 - accuracy: 0.8305 - val_loss: 0.5839 - val_accuracy: 0.7877\n",
            "Epoch 122/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4438 - accuracy: 0.8305 - val_loss: 0.5660 - val_accuracy: 0.7877\n",
            "Epoch 123/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4399 - accuracy: 0.8376 - val_loss: 0.5867 - val_accuracy: 0.7724\n",
            "Epoch 124/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4475 - accuracy: 0.8367 - val_loss: 0.5578 - val_accuracy: 0.7866\n",
            "Epoch 125/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4375 - accuracy: 0.8340 - val_loss: 0.5816 - val_accuracy: 0.7972\n",
            "Epoch 126/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4393 - accuracy: 0.8370 - val_loss: 0.5657 - val_accuracy: 0.7925\n",
            "Epoch 127/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4383 - accuracy: 0.8405 - val_loss: 0.5685 - val_accuracy: 0.7948\n",
            "Epoch 128/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4364 - accuracy: 0.8381 - val_loss: 0.5636 - val_accuracy: 0.7925\n",
            "Epoch 129/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4361 - accuracy: 0.8346 - val_loss: 0.5666 - val_accuracy: 0.8042\n",
            "Epoch 130/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4354 - accuracy: 0.8381 - val_loss: 0.5657 - val_accuracy: 0.7866\n",
            "Epoch 131/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4272 - accuracy: 0.8399 - val_loss: 0.5946 - val_accuracy: 0.7877\n",
            "Epoch 132/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4263 - accuracy: 0.8443 - val_loss: 0.5676 - val_accuracy: 0.7889\n",
            "Epoch 133/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4242 - accuracy: 0.8408 - val_loss: 0.5855 - val_accuracy: 0.7925\n",
            "Epoch 134/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4327 - accuracy: 0.8438 - val_loss: 0.5624 - val_accuracy: 0.7901\n",
            "Epoch 135/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4224 - accuracy: 0.8432 - val_loss: 0.5541 - val_accuracy: 0.7925\n",
            "Epoch 136/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4219 - accuracy: 0.8440 - val_loss: 0.5577 - val_accuracy: 0.7960\n",
            "Epoch 137/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4207 - accuracy: 0.8470 - val_loss: 0.5713 - val_accuracy: 0.7983\n",
            "Epoch 138/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4223 - accuracy: 0.8435 - val_loss: 0.5563 - val_accuracy: 0.7936\n",
            "Epoch 139/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4178 - accuracy: 0.8455 - val_loss: 0.5558 - val_accuracy: 0.7960\n",
            "Epoch 140/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4174 - accuracy: 0.8458 - val_loss: 0.5594 - val_accuracy: 0.7972\n",
            "Epoch 141/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4135 - accuracy: 0.8488 - val_loss: 0.5836 - val_accuracy: 0.7736\n",
            "Epoch 142/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4137 - accuracy: 0.8464 - val_loss: 0.5784 - val_accuracy: 0.7830\n",
            "Epoch 143/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4056 - accuracy: 0.8529 - val_loss: 0.5621 - val_accuracy: 0.7854\n",
            "Epoch 144/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4107 - accuracy: 0.8550 - val_loss: 0.5579 - val_accuracy: 0.7807\n",
            "Epoch 145/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4049 - accuracy: 0.8496 - val_loss: 0.5529 - val_accuracy: 0.7842\n",
            "Epoch 146/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4193 - accuracy: 0.8473 - val_loss: 0.5478 - val_accuracy: 0.7960\n",
            "Epoch 147/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4082 - accuracy: 0.8520 - val_loss: 0.5572 - val_accuracy: 0.7854\n",
            "Epoch 148/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3956 - accuracy: 0.8564 - val_loss: 0.5590 - val_accuracy: 0.7830\n",
            "Epoch 149/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.4014 - accuracy: 0.8529 - val_loss: 0.5546 - val_accuracy: 0.8031\n",
            "Epoch 150/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3978 - accuracy: 0.8547 - val_loss: 0.5560 - val_accuracy: 0.7877\n",
            "Epoch 151/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3984 - accuracy: 0.8505 - val_loss: 0.5768 - val_accuracy: 0.7748\n",
            "Epoch 152/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.4004 - accuracy: 0.8520 - val_loss: 0.5781 - val_accuracy: 0.7913\n",
            "Epoch 153/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3970 - accuracy: 0.8541 - val_loss: 0.5497 - val_accuracy: 0.7983\n",
            "Epoch 154/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3952 - accuracy: 0.8579 - val_loss: 0.5353 - val_accuracy: 0.8007\n",
            "Epoch 155/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3907 - accuracy: 0.8594 - val_loss: 0.5440 - val_accuracy: 0.8054\n",
            "Epoch 156/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3897 - accuracy: 0.8594 - val_loss: 0.5490 - val_accuracy: 0.7936\n",
            "Epoch 157/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3947 - accuracy: 0.8491 - val_loss: 0.5483 - val_accuracy: 0.8066\n",
            "Epoch 158/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3871 - accuracy: 0.8579 - val_loss: 0.5602 - val_accuracy: 0.7972\n",
            "Epoch 159/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3844 - accuracy: 0.8573 - val_loss: 0.5581 - val_accuracy: 0.7983\n",
            "Epoch 160/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3890 - accuracy: 0.8635 - val_loss: 0.5404 - val_accuracy: 0.8054\n",
            "Epoch 161/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3831 - accuracy: 0.8597 - val_loss: 0.5492 - val_accuracy: 0.7995\n",
            "Epoch 162/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3863 - accuracy: 0.8635 - val_loss: 0.5546 - val_accuracy: 0.8090\n",
            "Epoch 163/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3872 - accuracy: 0.8570 - val_loss: 0.5650 - val_accuracy: 0.8019\n",
            "Epoch 164/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3807 - accuracy: 0.8547 - val_loss: 0.5419 - val_accuracy: 0.7983\n",
            "Epoch 165/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3789 - accuracy: 0.8629 - val_loss: 0.5609 - val_accuracy: 0.8125\n",
            "Epoch 166/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3839 - accuracy: 0.8629 - val_loss: 0.5559 - val_accuracy: 0.8042\n",
            "Epoch 167/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3760 - accuracy: 0.8626 - val_loss: 0.5417 - val_accuracy: 0.7995\n",
            "Epoch 168/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3798 - accuracy: 0.8606 - val_loss: 0.5373 - val_accuracy: 0.8090\n",
            "Epoch 169/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3857 - accuracy: 0.8555 - val_loss: 0.5617 - val_accuracy: 0.8007\n",
            "Epoch 170/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3713 - accuracy: 0.8626 - val_loss: 0.5552 - val_accuracy: 0.7948\n",
            "Epoch 171/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3688 - accuracy: 0.8597 - val_loss: 0.5695 - val_accuracy: 0.7995\n",
            "Epoch 172/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3739 - accuracy: 0.8611 - val_loss: 0.5414 - val_accuracy: 0.7995\n",
            "Epoch 173/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3766 - accuracy: 0.8579 - val_loss: 0.5710 - val_accuracy: 0.7960\n",
            "Epoch 174/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3682 - accuracy: 0.8635 - val_loss: 0.5313 - val_accuracy: 0.8054\n",
            "Epoch 175/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3619 - accuracy: 0.8715 - val_loss: 0.5400 - val_accuracy: 0.8054\n",
            "Epoch 176/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3736 - accuracy: 0.8591 - val_loss: 0.5484 - val_accuracy: 0.8125\n",
            "Epoch 177/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3656 - accuracy: 0.8673 - val_loss: 0.5406 - val_accuracy: 0.7960\n",
            "Epoch 178/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3687 - accuracy: 0.8623 - val_loss: 0.5380 - val_accuracy: 0.8090\n",
            "Epoch 179/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3660 - accuracy: 0.8697 - val_loss: 0.5388 - val_accuracy: 0.8066\n",
            "Epoch 180/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3653 - accuracy: 0.8706 - val_loss: 0.5500 - val_accuracy: 0.8101\n",
            "Epoch 181/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3618 - accuracy: 0.8703 - val_loss: 0.5385 - val_accuracy: 0.7877\n",
            "Epoch 182/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 0.5452 - val_accuracy: 0.8042\n",
            "Epoch 183/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3628 - accuracy: 0.8673 - val_loss: 0.5331 - val_accuracy: 0.8196\n",
            "Epoch 184/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3581 - accuracy: 0.8738 - val_loss: 0.5393 - val_accuracy: 0.8007\n",
            "Epoch 185/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3566 - accuracy: 0.8706 - val_loss: 0.5428 - val_accuracy: 0.7842\n",
            "Epoch 186/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3550 - accuracy: 0.8732 - val_loss: 0.5467 - val_accuracy: 0.8066\n",
            "Epoch 187/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3552 - accuracy: 0.8721 - val_loss: 0.5546 - val_accuracy: 0.8066\n",
            "Epoch 188/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3490 - accuracy: 0.8735 - val_loss: 0.5339 - val_accuracy: 0.8078\n",
            "Epoch 189/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3553 - accuracy: 0.8741 - val_loss: 0.5244 - val_accuracy: 0.8031\n",
            "Epoch 190/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8753 - val_loss: 0.5459 - val_accuracy: 0.8101\n",
            "Epoch 191/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8726 - val_loss: 0.5351 - val_accuracy: 0.7995\n",
            "Epoch 192/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8744 - val_loss: 0.5447 - val_accuracy: 0.8019\n",
            "Epoch 193/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3478 - accuracy: 0.8706 - val_loss: 0.5332 - val_accuracy: 0.8149\n",
            "Epoch 194/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8723 - val_loss: 0.5278 - val_accuracy: 0.8137\n",
            "Epoch 195/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3348 - accuracy: 0.8815 - val_loss: 0.5396 - val_accuracy: 0.8160\n",
            "Epoch 196/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3390 - accuracy: 0.8723 - val_loss: 0.5314 - val_accuracy: 0.8125\n",
            "Epoch 197/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3430 - accuracy: 0.8747 - val_loss: 0.5283 - val_accuracy: 0.8090\n",
            "Epoch 198/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3376 - accuracy: 0.8747 - val_loss: 0.5422 - val_accuracy: 0.8031\n",
            "Epoch 199/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3403 - accuracy: 0.8706 - val_loss: 0.5499 - val_accuracy: 0.8101\n",
            "Epoch 200/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3284 - accuracy: 0.8777 - val_loss: 0.5267 - val_accuracy: 0.8231\n",
            "Epoch 201/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3243 - accuracy: 0.8824 - val_loss: 0.5288 - val_accuracy: 0.8137\n",
            "Epoch 202/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3363 - accuracy: 0.8762 - val_loss: 0.5300 - val_accuracy: 0.8066\n",
            "Epoch 203/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3291 - accuracy: 0.8753 - val_loss: 0.5303 - val_accuracy: 0.8149\n",
            "Epoch 204/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3322 - accuracy: 0.8777 - val_loss: 0.5646 - val_accuracy: 0.8137\n",
            "Epoch 205/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3270 - accuracy: 0.8785 - val_loss: 0.5675 - val_accuracy: 0.7995\n",
            "Epoch 206/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3291 - accuracy: 0.8833 - val_loss: 0.5309 - val_accuracy: 0.7936\n",
            "Epoch 207/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3335 - accuracy: 0.8765 - val_loss: 0.5399 - val_accuracy: 0.8125\n",
            "Epoch 208/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3205 - accuracy: 0.8815 - val_loss: 0.5579 - val_accuracy: 0.8101\n",
            "Epoch 209/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3258 - accuracy: 0.8827 - val_loss: 0.5472 - val_accuracy: 0.8066\n",
            "Epoch 210/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3218 - accuracy: 0.8809 - val_loss: 0.5373 - val_accuracy: 0.7995\n",
            "Epoch 211/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3153 - accuracy: 0.8841 - val_loss: 0.5322 - val_accuracy: 0.8196\n",
            "Epoch 212/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3215 - accuracy: 0.8777 - val_loss: 0.5223 - val_accuracy: 0.8078\n",
            "Epoch 213/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3201 - accuracy: 0.8844 - val_loss: 0.5388 - val_accuracy: 0.8278\n",
            "Epoch 214/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3174 - accuracy: 0.8844 - val_loss: 0.5273 - val_accuracy: 0.8101\n",
            "Epoch 215/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3242 - accuracy: 0.8794 - val_loss: 0.5325 - val_accuracy: 0.8078\n",
            "Epoch 216/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3204 - accuracy: 0.8841 - val_loss: 0.5498 - val_accuracy: 0.8031\n",
            "Epoch 217/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3185 - accuracy: 0.8794 - val_loss: 0.5484 - val_accuracy: 0.8125\n",
            "Epoch 218/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3154 - accuracy: 0.8821 - val_loss: 0.5182 - val_accuracy: 0.8196\n",
            "Epoch 219/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3177 - accuracy: 0.8818 - val_loss: 0.5267 - val_accuracy: 0.8113\n",
            "Epoch 220/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3061 - accuracy: 0.8835 - val_loss: 0.5288 - val_accuracy: 0.8090\n",
            "Epoch 221/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3112 - accuracy: 0.8841 - val_loss: 0.5434 - val_accuracy: 0.8066\n",
            "Epoch 222/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3009 - accuracy: 0.8924 - val_loss: 0.5245 - val_accuracy: 0.8172\n",
            "Epoch 223/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3053 - accuracy: 0.8897 - val_loss: 0.5386 - val_accuracy: 0.8042\n",
            "Epoch 224/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3119 - accuracy: 0.8841 - val_loss: 0.5291 - val_accuracy: 0.8031\n",
            "Epoch 225/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2989 - accuracy: 0.8871 - val_loss: 0.5521 - val_accuracy: 0.8149\n",
            "Epoch 226/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3093 - accuracy: 0.8900 - val_loss: 0.5329 - val_accuracy: 0.8267\n",
            "Epoch 227/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2972 - accuracy: 0.8924 - val_loss: 0.5185 - val_accuracy: 0.8090\n",
            "Epoch 228/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3080 - accuracy: 0.8859 - val_loss: 0.5213 - val_accuracy: 0.8160\n",
            "Epoch 229/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3028 - accuracy: 0.8841 - val_loss: 0.5820 - val_accuracy: 0.8078\n",
            "Epoch 230/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.3016 - accuracy: 0.8856 - val_loss: 0.5409 - val_accuracy: 0.8160\n",
            "Epoch 231/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3057 - accuracy: 0.8883 - val_loss: 0.5328 - val_accuracy: 0.8219\n",
            "Epoch 232/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2999 - accuracy: 0.8903 - val_loss: 0.5459 - val_accuracy: 0.8031\n",
            "Epoch 233/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2975 - accuracy: 0.8897 - val_loss: 0.5377 - val_accuracy: 0.8325\n",
            "Epoch 234/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2956 - accuracy: 0.8892 - val_loss: 0.5420 - val_accuracy: 0.8231\n",
            "Epoch 235/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2938 - accuracy: 0.8906 - val_loss: 0.5297 - val_accuracy: 0.8149\n",
            "Epoch 236/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2969 - accuracy: 0.8927 - val_loss: 0.5228 - val_accuracy: 0.8208\n",
            "Epoch 237/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.3026 - accuracy: 0.8889 - val_loss: 0.5320 - val_accuracy: 0.8125\n",
            "Epoch 238/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2902 - accuracy: 0.8962 - val_loss: 0.5288 - val_accuracy: 0.8172\n",
            "Epoch 239/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2992 - accuracy: 0.8886 - val_loss: 0.5441 - val_accuracy: 0.8231\n",
            "Epoch 240/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2822 - accuracy: 0.8959 - val_loss: 0.5346 - val_accuracy: 0.8302\n",
            "Epoch 241/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2829 - accuracy: 0.8939 - val_loss: 0.5380 - val_accuracy: 0.8278\n",
            "Epoch 242/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2878 - accuracy: 0.8950 - val_loss: 0.5228 - val_accuracy: 0.8231\n",
            "Epoch 243/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2776 - accuracy: 0.8959 - val_loss: 0.5511 - val_accuracy: 0.8078\n",
            "Epoch 244/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2923 - accuracy: 0.8915 - val_loss: 0.5309 - val_accuracy: 0.8255\n",
            "Epoch 245/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2800 - accuracy: 0.8918 - val_loss: 0.5283 - val_accuracy: 0.8278\n",
            "Epoch 246/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2896 - accuracy: 0.8939 - val_loss: 0.5520 - val_accuracy: 0.8113\n",
            "Epoch 247/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2884 - accuracy: 0.8980 - val_loss: 0.5267 - val_accuracy: 0.8172\n",
            "Epoch 248/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2837 - accuracy: 0.8995 - val_loss: 0.5230 - val_accuracy: 0.8208\n",
            "Epoch 249/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2760 - accuracy: 0.8962 - val_loss: 0.5454 - val_accuracy: 0.8184\n",
            "Epoch 250/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2808 - accuracy: 0.8989 - val_loss: 0.5240 - val_accuracy: 0.8160\n",
            "Epoch 251/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2758 - accuracy: 0.8983 - val_loss: 0.5341 - val_accuracy: 0.8231\n",
            "Epoch 252/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2780 - accuracy: 0.9015 - val_loss: 0.5289 - val_accuracy: 0.8160\n",
            "Epoch 253/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2718 - accuracy: 0.9009 - val_loss: 0.5177 - val_accuracy: 0.8302\n",
            "Epoch 254/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2749 - accuracy: 0.8965 - val_loss: 0.5276 - val_accuracy: 0.8243\n",
            "Epoch 255/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2743 - accuracy: 0.9030 - val_loss: 0.5204 - val_accuracy: 0.8208\n",
            "Epoch 256/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2702 - accuracy: 0.9027 - val_loss: 0.5341 - val_accuracy: 0.8160\n",
            "Epoch 257/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2636 - accuracy: 0.8968 - val_loss: 0.5270 - val_accuracy: 0.8125\n",
            "Epoch 258/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2659 - accuracy: 0.9001 - val_loss: 0.5196 - val_accuracy: 0.8337\n",
            "Epoch 259/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2661 - accuracy: 0.9004 - val_loss: 0.5087 - val_accuracy: 0.8208\n",
            "Epoch 260/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2671 - accuracy: 0.9054 - val_loss: 0.5390 - val_accuracy: 0.8184\n",
            "Epoch 261/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2639 - accuracy: 0.9051 - val_loss: 0.5453 - val_accuracy: 0.7960\n",
            "Epoch 262/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2604 - accuracy: 0.9036 - val_loss: 0.5197 - val_accuracy: 0.8231\n",
            "Epoch 263/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2599 - accuracy: 0.9024 - val_loss: 0.5306 - val_accuracy: 0.8172\n",
            "Epoch 264/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2720 - accuracy: 0.9021 - val_loss: 0.5182 - val_accuracy: 0.8267\n",
            "Epoch 265/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2557 - accuracy: 0.9083 - val_loss: 0.5096 - val_accuracy: 0.8278\n",
            "Epoch 266/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2661 - accuracy: 0.9004 - val_loss: 0.5218 - val_accuracy: 0.8208\n",
            "Epoch 267/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2713 - accuracy: 0.9024 - val_loss: 0.5128 - val_accuracy: 0.8290\n",
            "Epoch 268/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2633 - accuracy: 0.8998 - val_loss: 0.5316 - val_accuracy: 0.8302\n",
            "Epoch 269/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2642 - accuracy: 0.9021 - val_loss: 0.5153 - val_accuracy: 0.8361\n",
            "Epoch 270/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2598 - accuracy: 0.9027 - val_loss: 0.5508 - val_accuracy: 0.8078\n",
            "Epoch 271/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2566 - accuracy: 0.9062 - val_loss: 0.5421 - val_accuracy: 0.8101\n",
            "Epoch 272/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2563 - accuracy: 0.9036 - val_loss: 0.5337 - val_accuracy: 0.8255\n",
            "Epoch 273/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2563 - accuracy: 0.9030 - val_loss: 0.5088 - val_accuracy: 0.8325\n",
            "Epoch 274/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2617 - accuracy: 0.9068 - val_loss: 0.5160 - val_accuracy: 0.8267\n",
            "Epoch 275/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2609 - accuracy: 0.9051 - val_loss: 0.5325 - val_accuracy: 0.8160\n",
            "Epoch 276/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2608 - accuracy: 0.8992 - val_loss: 0.5288 - val_accuracy: 0.8196\n",
            "Epoch 277/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2634 - accuracy: 0.9065 - val_loss: 0.5213 - val_accuracy: 0.8243\n",
            "Epoch 278/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2495 - accuracy: 0.9074 - val_loss: 0.5332 - val_accuracy: 0.8137\n",
            "Epoch 279/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2564 - accuracy: 0.9033 - val_loss: 0.5166 - val_accuracy: 0.8290\n",
            "Epoch 280/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2534 - accuracy: 0.9060 - val_loss: 0.5277 - val_accuracy: 0.8149\n",
            "Epoch 281/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2513 - accuracy: 0.9089 - val_loss: 0.5034 - val_accuracy: 0.8396\n",
            "Epoch 282/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2451 - accuracy: 0.9119 - val_loss: 0.5017 - val_accuracy: 0.8267\n",
            "Epoch 283/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2437 - accuracy: 0.9121 - val_loss: 0.5233 - val_accuracy: 0.8325\n",
            "Epoch 284/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2396 - accuracy: 0.9127 - val_loss: 0.5243 - val_accuracy: 0.8184\n",
            "Epoch 285/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2431 - accuracy: 0.9092 - val_loss: 0.5234 - val_accuracy: 0.8290\n",
            "Epoch 286/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2394 - accuracy: 0.9095 - val_loss: 0.5639 - val_accuracy: 0.8042\n",
            "Epoch 287/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2458 - accuracy: 0.9077 - val_loss: 0.5135 - val_accuracy: 0.8302\n",
            "Epoch 288/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2394 - accuracy: 0.9186 - val_loss: 0.5238 - val_accuracy: 0.8384\n",
            "Epoch 289/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2441 - accuracy: 0.9113 - val_loss: 0.5665 - val_accuracy: 0.8019\n",
            "Epoch 290/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2364 - accuracy: 0.9139 - val_loss: 0.5185 - val_accuracy: 0.8255\n",
            "Epoch 291/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2366 - accuracy: 0.9107 - val_loss: 0.5156 - val_accuracy: 0.8361\n",
            "Epoch 292/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2312 - accuracy: 0.9139 - val_loss: 0.5204 - val_accuracy: 0.8160\n",
            "Epoch 293/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2341 - accuracy: 0.9151 - val_loss: 0.5293 - val_accuracy: 0.8337\n",
            "Epoch 294/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2216 - accuracy: 0.9201 - val_loss: 0.5283 - val_accuracy: 0.8172\n",
            "Epoch 295/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2386 - accuracy: 0.9136 - val_loss: 0.5056 - val_accuracy: 0.8243\n",
            "Epoch 296/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2381 - accuracy: 0.9127 - val_loss: 0.5266 - val_accuracy: 0.8314\n",
            "Epoch 297/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2292 - accuracy: 0.9154 - val_loss: 0.5220 - val_accuracy: 0.8302\n",
            "Epoch 298/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2263 - accuracy: 0.9175 - val_loss: 0.5366 - val_accuracy: 0.8278\n",
            "Epoch 299/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2287 - accuracy: 0.9160 - val_loss: 0.5156 - val_accuracy: 0.8314\n",
            "Epoch 300/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2318 - accuracy: 0.9127 - val_loss: 0.5233 - val_accuracy: 0.8267\n",
            "Epoch 301/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2273 - accuracy: 0.9189 - val_loss: 0.5077 - val_accuracy: 0.8325\n",
            "Epoch 302/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2277 - accuracy: 0.9186 - val_loss: 0.5102 - val_accuracy: 0.8384\n",
            "Epoch 303/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2275 - accuracy: 0.9222 - val_loss: 0.5469 - val_accuracy: 0.8160\n",
            "Epoch 304/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2263 - accuracy: 0.9160 - val_loss: 0.5255 - val_accuracy: 0.8396\n",
            "Epoch 305/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2288 - accuracy: 0.9195 - val_loss: 0.5391 - val_accuracy: 0.8408\n",
            "Epoch 306/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2304 - accuracy: 0.9177 - val_loss: 0.5262 - val_accuracy: 0.8314\n",
            "Epoch 307/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2312 - accuracy: 0.9157 - val_loss: 0.5275 - val_accuracy: 0.8337\n",
            "Epoch 308/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2240 - accuracy: 0.9157 - val_loss: 0.5232 - val_accuracy: 0.8361\n",
            "Epoch 309/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2206 - accuracy: 0.9207 - val_loss: 0.5101 - val_accuracy: 0.8325\n",
            "Epoch 310/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2327 - accuracy: 0.9133 - val_loss: 0.5033 - val_accuracy: 0.8432\n",
            "Epoch 311/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2167 - accuracy: 0.9248 - val_loss: 0.5451 - val_accuracy: 0.8302\n",
            "Epoch 312/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2169 - accuracy: 0.9225 - val_loss: 0.5324 - val_accuracy: 0.8314\n",
            "Epoch 313/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2208 - accuracy: 0.9228 - val_loss: 0.5229 - val_accuracy: 0.8408\n",
            "Epoch 314/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2181 - accuracy: 0.9213 - val_loss: 0.5235 - val_accuracy: 0.8255\n",
            "Epoch 315/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2172 - accuracy: 0.9186 - val_loss: 0.5279 - val_accuracy: 0.8361\n",
            "Epoch 316/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2143 - accuracy: 0.9189 - val_loss: 0.5418 - val_accuracy: 0.8255\n",
            "Epoch 317/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2261 - accuracy: 0.9177 - val_loss: 0.5191 - val_accuracy: 0.8267\n",
            "Epoch 318/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2138 - accuracy: 0.9213 - val_loss: 0.5216 - val_accuracy: 0.8337\n",
            "Epoch 319/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2195 - accuracy: 0.9160 - val_loss: 0.5256 - val_accuracy: 0.8290\n",
            "Epoch 320/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2168 - accuracy: 0.9210 - val_loss: 0.5065 - val_accuracy: 0.8361\n",
            "Epoch 321/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2092 - accuracy: 0.9195 - val_loss: 0.5249 - val_accuracy: 0.8290\n",
            "Epoch 322/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2061 - accuracy: 0.9231 - val_loss: 0.5526 - val_accuracy: 0.8160\n",
            "Epoch 323/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.5522 - val_accuracy: 0.8314\n",
            "Epoch 324/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2120 - accuracy: 0.9192 - val_loss: 0.5233 - val_accuracy: 0.8420\n",
            "Epoch 325/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2076 - accuracy: 0.9207 - val_loss: 0.5437 - val_accuracy: 0.8149\n",
            "Epoch 326/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1937 - accuracy: 0.9313 - val_loss: 0.5081 - val_accuracy: 0.8314\n",
            "Epoch 327/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2103 - accuracy: 0.9263 - val_loss: 0.5231 - val_accuracy: 0.8302\n",
            "Epoch 328/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2106 - accuracy: 0.9254 - val_loss: 0.5164 - val_accuracy: 0.8396\n",
            "Epoch 329/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2011 - accuracy: 0.9263 - val_loss: 0.5318 - val_accuracy: 0.8491\n",
            "Epoch 330/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2078 - accuracy: 0.9228 - val_loss: 0.5273 - val_accuracy: 0.8349\n",
            "Epoch 331/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.2094 - accuracy: 0.9242 - val_loss: 0.5164 - val_accuracy: 0.8325\n",
            "Epoch 332/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1975 - accuracy: 0.9278 - val_loss: 0.5319 - val_accuracy: 0.8384\n",
            "Epoch 333/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1997 - accuracy: 0.9278 - val_loss: 0.5159 - val_accuracy: 0.8432\n",
            "Epoch 334/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2008 - accuracy: 0.9248 - val_loss: 0.5427 - val_accuracy: 0.8208\n",
            "Epoch 335/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1993 - accuracy: 0.9260 - val_loss: 0.5038 - val_accuracy: 0.8538\n",
            "Epoch 336/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2016 - accuracy: 0.9266 - val_loss: 0.5101 - val_accuracy: 0.8384\n",
            "Epoch 337/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2024 - accuracy: 0.9251 - val_loss: 0.5098 - val_accuracy: 0.8290\n",
            "Epoch 338/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1870 - accuracy: 0.9292 - val_loss: 0.5059 - val_accuracy: 0.8467\n",
            "Epoch 339/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1908 - accuracy: 0.9307 - val_loss: 0.5535 - val_accuracy: 0.8219\n",
            "Epoch 340/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1980 - accuracy: 0.9281 - val_loss: 0.5546 - val_accuracy: 0.8137\n",
            "Epoch 341/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1969 - accuracy: 0.9292 - val_loss: 0.5391 - val_accuracy: 0.8314\n",
            "Epoch 342/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1925 - accuracy: 0.9278 - val_loss: 0.5105 - val_accuracy: 0.8432\n",
            "Epoch 343/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1929 - accuracy: 0.9281 - val_loss: 0.5163 - val_accuracy: 0.8302\n",
            "Epoch 344/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1887 - accuracy: 0.9328 - val_loss: 0.5233 - val_accuracy: 0.8396\n",
            "Epoch 345/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1860 - accuracy: 0.9284 - val_loss: 0.5239 - val_accuracy: 0.8290\n",
            "Epoch 346/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1956 - accuracy: 0.9284 - val_loss: 0.5063 - val_accuracy: 0.8432\n",
            "Epoch 347/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1946 - accuracy: 0.9292 - val_loss: 0.5253 - val_accuracy: 0.8337\n",
            "Epoch 348/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1901 - accuracy: 0.9310 - val_loss: 0.5447 - val_accuracy: 0.8349\n",
            "Epoch 349/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.2041 - accuracy: 0.9248 - val_loss: 0.5486 - val_accuracy: 0.8302\n",
            "Epoch 350/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1920 - accuracy: 0.9281 - val_loss: 0.5322 - val_accuracy: 0.8290\n",
            "Epoch 351/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1920 - accuracy: 0.9301 - val_loss: 0.5500 - val_accuracy: 0.8196\n",
            "Epoch 352/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1814 - accuracy: 0.9340 - val_loss: 0.5405 - val_accuracy: 0.8373\n",
            "Epoch 353/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1887 - accuracy: 0.9266 - val_loss: 0.5328 - val_accuracy: 0.8361\n",
            "Epoch 354/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1842 - accuracy: 0.9351 - val_loss: 0.5298 - val_accuracy: 0.8278\n",
            "Epoch 355/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1821 - accuracy: 0.9337 - val_loss: 0.5185 - val_accuracy: 0.8337\n",
            "Epoch 356/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1855 - accuracy: 0.9304 - val_loss: 0.5263 - val_accuracy: 0.8420\n",
            "Epoch 357/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1810 - accuracy: 0.9360 - val_loss: 0.5317 - val_accuracy: 0.8302\n",
            "Epoch 358/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1869 - accuracy: 0.9298 - val_loss: 0.5042 - val_accuracy: 0.8373\n",
            "Epoch 359/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1807 - accuracy: 0.9322 - val_loss: 0.5312 - val_accuracy: 0.8408\n",
            "Epoch 360/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1761 - accuracy: 0.9381 - val_loss: 0.5260 - val_accuracy: 0.8325\n",
            "Epoch 361/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1836 - accuracy: 0.9343 - val_loss: 0.5208 - val_accuracy: 0.8361\n",
            "Epoch 362/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1867 - accuracy: 0.9331 - val_loss: 0.5238 - val_accuracy: 0.8337\n",
            "Epoch 363/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1780 - accuracy: 0.9360 - val_loss: 0.5311 - val_accuracy: 0.8278\n",
            "Epoch 364/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1735 - accuracy: 0.9407 - val_loss: 0.5315 - val_accuracy: 0.8396\n",
            "Epoch 365/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1710 - accuracy: 0.9357 - val_loss: 0.5433 - val_accuracy: 0.8337\n",
            "Epoch 366/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1755 - accuracy: 0.9402 - val_loss: 0.5454 - val_accuracy: 0.8420\n",
            "Epoch 367/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1852 - accuracy: 0.9328 - val_loss: 0.5305 - val_accuracy: 0.8373\n",
            "Epoch 368/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1785 - accuracy: 0.9399 - val_loss: 0.5337 - val_accuracy: 0.8432\n",
            "Epoch 369/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1824 - accuracy: 0.9340 - val_loss: 0.5175 - val_accuracy: 0.8467\n",
            "Epoch 370/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1732 - accuracy: 0.9372 - val_loss: 0.5655 - val_accuracy: 0.8290\n",
            "Epoch 371/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1697 - accuracy: 0.9351 - val_loss: 0.5236 - val_accuracy: 0.8361\n",
            "Epoch 372/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1653 - accuracy: 0.9369 - val_loss: 0.5493 - val_accuracy: 0.8302\n",
            "Epoch 373/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1663 - accuracy: 0.9410 - val_loss: 0.5348 - val_accuracy: 0.8420\n",
            "Epoch 374/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1753 - accuracy: 0.9375 - val_loss: 0.5120 - val_accuracy: 0.8373\n",
            "Epoch 375/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1743 - accuracy: 0.9351 - val_loss: 0.5091 - val_accuracy: 0.8420\n",
            "Epoch 376/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1660 - accuracy: 0.9387 - val_loss: 0.5411 - val_accuracy: 0.8420\n",
            "Epoch 377/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1754 - accuracy: 0.9360 - val_loss: 0.5413 - val_accuracy: 0.8314\n",
            "Epoch 378/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1737 - accuracy: 0.9340 - val_loss: 0.5182 - val_accuracy: 0.8514\n",
            "Epoch 379/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1669 - accuracy: 0.9402 - val_loss: 0.5128 - val_accuracy: 0.8384\n",
            "Epoch 380/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1643 - accuracy: 0.9372 - val_loss: 0.5128 - val_accuracy: 0.8384\n",
            "Epoch 381/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1636 - accuracy: 0.9399 - val_loss: 0.5512 - val_accuracy: 0.8184\n",
            "Epoch 382/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1564 - accuracy: 0.9416 - val_loss: 0.5575 - val_accuracy: 0.8208\n",
            "Epoch 383/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1618 - accuracy: 0.9375 - val_loss: 0.5249 - val_accuracy: 0.8479\n",
            "Epoch 384/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1656 - accuracy: 0.9378 - val_loss: 0.5531 - val_accuracy: 0.8467\n",
            "Epoch 385/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1584 - accuracy: 0.9475 - val_loss: 0.5353 - val_accuracy: 0.8443\n",
            "Epoch 386/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1613 - accuracy: 0.9404 - val_loss: 0.5359 - val_accuracy: 0.8432\n",
            "Epoch 387/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1610 - accuracy: 0.9402 - val_loss: 0.5522 - val_accuracy: 0.8267\n",
            "Epoch 388/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1590 - accuracy: 0.9431 - val_loss: 0.6014 - val_accuracy: 0.8208\n",
            "Epoch 389/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1731 - accuracy: 0.9372 - val_loss: 0.5445 - val_accuracy: 0.8361\n",
            "Epoch 390/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1642 - accuracy: 0.9407 - val_loss: 0.5396 - val_accuracy: 0.8196\n",
            "Epoch 391/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1598 - accuracy: 0.9407 - val_loss: 0.5466 - val_accuracy: 0.8231\n",
            "Epoch 392/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1536 - accuracy: 0.9452 - val_loss: 0.5445 - val_accuracy: 0.8337\n",
            "Epoch 393/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1530 - accuracy: 0.9481 - val_loss: 0.5170 - val_accuracy: 0.8443\n",
            "Epoch 394/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1572 - accuracy: 0.9413 - val_loss: 0.5462 - val_accuracy: 0.8432\n",
            "Epoch 395/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1577 - accuracy: 0.9463 - val_loss: 0.5125 - val_accuracy: 0.8384\n",
            "Epoch 396/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1589 - accuracy: 0.9443 - val_loss: 0.5354 - val_accuracy: 0.8337\n",
            "Epoch 397/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1538 - accuracy: 0.9449 - val_loss: 0.5346 - val_accuracy: 0.8361\n",
            "Epoch 398/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1533 - accuracy: 0.9425 - val_loss: 0.5458 - val_accuracy: 0.8325\n",
            "Epoch 399/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1574 - accuracy: 0.9440 - val_loss: 0.5122 - val_accuracy: 0.8420\n",
            "Epoch 400/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1546 - accuracy: 0.9460 - val_loss: 0.5430 - val_accuracy: 0.8420\n",
            "Epoch 401/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1565 - accuracy: 0.9478 - val_loss: 0.5276 - val_accuracy: 0.8408\n",
            "Epoch 402/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1464 - accuracy: 0.9455 - val_loss: 0.5427 - val_accuracy: 0.8267\n",
            "Epoch 403/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1569 - accuracy: 0.9458 - val_loss: 0.5302 - val_accuracy: 0.8396\n",
            "Epoch 404/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1559 - accuracy: 0.9431 - val_loss: 0.5403 - val_accuracy: 0.8396\n",
            "Epoch 405/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1602 - accuracy: 0.9402 - val_loss: 0.5446 - val_accuracy: 0.8290\n",
            "Epoch 406/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1522 - accuracy: 0.9496 - val_loss: 0.5258 - val_accuracy: 0.8408\n",
            "Epoch 407/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1537 - accuracy: 0.9437 - val_loss: 0.5428 - val_accuracy: 0.8290\n",
            "Epoch 408/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1512 - accuracy: 0.9434 - val_loss: 0.5104 - val_accuracy: 0.8443\n",
            "Epoch 409/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1421 - accuracy: 0.9452 - val_loss: 0.5354 - val_accuracy: 0.8396\n",
            "Epoch 410/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1564 - accuracy: 0.9449 - val_loss: 0.5238 - val_accuracy: 0.8420\n",
            "Epoch 411/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1459 - accuracy: 0.9490 - val_loss: 0.5454 - val_accuracy: 0.8337\n",
            "Epoch 412/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1508 - accuracy: 0.9425 - val_loss: 0.5487 - val_accuracy: 0.8337\n",
            "Epoch 413/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1521 - accuracy: 0.9434 - val_loss: 0.5355 - val_accuracy: 0.8455\n",
            "Epoch 414/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1442 - accuracy: 0.9446 - val_loss: 0.5176 - val_accuracy: 0.8443\n",
            "Epoch 415/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1385 - accuracy: 0.9505 - val_loss: 0.5611 - val_accuracy: 0.8337\n",
            "Epoch 416/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1373 - accuracy: 0.9475 - val_loss: 0.5427 - val_accuracy: 0.8443\n",
            "Epoch 417/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1420 - accuracy: 0.9481 - val_loss: 0.5214 - val_accuracy: 0.8267\n",
            "Epoch 418/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1438 - accuracy: 0.9481 - val_loss: 0.5483 - val_accuracy: 0.8337\n",
            "Epoch 419/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1506 - accuracy: 0.9469 - val_loss: 0.5301 - val_accuracy: 0.8349\n",
            "Epoch 420/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1455 - accuracy: 0.9487 - val_loss: 0.5161 - val_accuracy: 0.8396\n",
            "Epoch 421/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1465 - accuracy: 0.9452 - val_loss: 0.5256 - val_accuracy: 0.8538\n",
            "Epoch 422/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1451 - accuracy: 0.9466 - val_loss: 0.5344 - val_accuracy: 0.8467\n",
            "Epoch 423/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1485 - accuracy: 0.9496 - val_loss: 0.5402 - val_accuracy: 0.8302\n",
            "Epoch 424/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1396 - accuracy: 0.9537 - val_loss: 0.5656 - val_accuracy: 0.8467\n",
            "Epoch 425/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1447 - accuracy: 0.9472 - val_loss: 0.5449 - val_accuracy: 0.8337\n",
            "Epoch 426/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1338 - accuracy: 0.9537 - val_loss: 0.5324 - val_accuracy: 0.8443\n",
            "Epoch 427/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1381 - accuracy: 0.9525 - val_loss: 0.5431 - val_accuracy: 0.8514\n",
            "Epoch 428/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1437 - accuracy: 0.9525 - val_loss: 0.5317 - val_accuracy: 0.8373\n",
            "Epoch 429/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1380 - accuracy: 0.9496 - val_loss: 0.5310 - val_accuracy: 0.8514\n",
            "Epoch 430/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1291 - accuracy: 0.9561 - val_loss: 0.5639 - val_accuracy: 0.8455\n",
            "Epoch 431/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1382 - accuracy: 0.9502 - val_loss: 0.5395 - val_accuracy: 0.8443\n",
            "Epoch 432/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1324 - accuracy: 0.9511 - val_loss: 0.5452 - val_accuracy: 0.8384\n",
            "Epoch 433/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1324 - accuracy: 0.9517 - val_loss: 0.5668 - val_accuracy: 0.8337\n",
            "Epoch 434/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1331 - accuracy: 0.9525 - val_loss: 0.5287 - val_accuracy: 0.8467\n",
            "Epoch 435/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1336 - accuracy: 0.9490 - val_loss: 0.5437 - val_accuracy: 0.8514\n",
            "Epoch 436/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1273 - accuracy: 0.9499 - val_loss: 0.5475 - val_accuracy: 0.8455\n",
            "Epoch 437/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1308 - accuracy: 0.9502 - val_loss: 0.5556 - val_accuracy: 0.8349\n",
            "Epoch 438/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1204 - accuracy: 0.9567 - val_loss: 0.5686 - val_accuracy: 0.8243\n",
            "Epoch 439/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1370 - accuracy: 0.9466 - val_loss: 0.5591 - val_accuracy: 0.8467\n",
            "Epoch 440/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1384 - accuracy: 0.9493 - val_loss: 0.5321 - val_accuracy: 0.8443\n",
            "Epoch 441/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1295 - accuracy: 0.9555 - val_loss: 0.5340 - val_accuracy: 0.8491\n",
            "Epoch 442/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1233 - accuracy: 0.9558 - val_loss: 0.5515 - val_accuracy: 0.8432\n",
            "Epoch 443/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1338 - accuracy: 0.9531 - val_loss: 0.5516 - val_accuracy: 0.8361\n",
            "Epoch 444/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1315 - accuracy: 0.9531 - val_loss: 0.5500 - val_accuracy: 0.8455\n",
            "Epoch 445/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1399 - accuracy: 0.9496 - val_loss: 0.5729 - val_accuracy: 0.8373\n",
            "Epoch 446/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1227 - accuracy: 0.9552 - val_loss: 0.5562 - val_accuracy: 0.8408\n",
            "Epoch 447/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1302 - accuracy: 0.9534 - val_loss: 0.6002 - val_accuracy: 0.8373\n",
            "Epoch 448/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1219 - accuracy: 0.9587 - val_loss: 0.5387 - val_accuracy: 0.8396\n",
            "Epoch 449/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1304 - accuracy: 0.9540 - val_loss: 0.5647 - val_accuracy: 0.8491\n",
            "Epoch 450/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1268 - accuracy: 0.9540 - val_loss: 0.5416 - val_accuracy: 0.8408\n",
            "Epoch 451/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1219 - accuracy: 0.9537 - val_loss: 0.5429 - val_accuracy: 0.8420\n",
            "Epoch 452/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1264 - accuracy: 0.9508 - val_loss: 0.5581 - val_accuracy: 0.8408\n",
            "Epoch 453/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1164 - accuracy: 0.9590 - val_loss: 0.5646 - val_accuracy: 0.8455\n",
            "Epoch 454/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1303 - accuracy: 0.9537 - val_loss: 0.5385 - val_accuracy: 0.8384\n",
            "Epoch 455/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1250 - accuracy: 0.9578 - val_loss: 0.5687 - val_accuracy: 0.8337\n",
            "Epoch 456/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1268 - accuracy: 0.9558 - val_loss: 0.5488 - val_accuracy: 0.8408\n",
            "Epoch 457/1300\n",
            "212/212 [==============================] - 2s 9ms/step - loss: 0.1164 - accuracy: 0.9605 - val_loss: 0.5347 - val_accuracy: 0.8526\n",
            "Epoch 458/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1289 - accuracy: 0.9543 - val_loss: 0.5614 - val_accuracy: 0.8467\n",
            "Epoch 459/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1146 - accuracy: 0.9602 - val_loss: 0.5413 - val_accuracy: 0.8443\n",
            "Epoch 460/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1192 - accuracy: 0.9578 - val_loss: 0.5559 - val_accuracy: 0.8467\n",
            "Epoch 461/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1120 - accuracy: 0.9596 - val_loss: 0.5793 - val_accuracy: 0.8432\n",
            "Epoch 462/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1152 - accuracy: 0.9602 - val_loss: 0.5435 - val_accuracy: 0.8361\n",
            "Epoch 463/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1261 - accuracy: 0.9552 - val_loss: 0.5701 - val_accuracy: 0.8349\n",
            "Epoch 464/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1161 - accuracy: 0.9575 - val_loss: 0.5468 - val_accuracy: 0.8384\n",
            "Epoch 465/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1160 - accuracy: 0.9567 - val_loss: 0.5568 - val_accuracy: 0.8491\n",
            "Epoch 466/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1177 - accuracy: 0.9605 - val_loss: 0.5599 - val_accuracy: 0.8384\n",
            "Epoch 467/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1244 - accuracy: 0.9555 - val_loss: 0.5554 - val_accuracy: 0.8597\n",
            "Epoch 468/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1154 - accuracy: 0.9614 - val_loss: 0.5789 - val_accuracy: 0.8514\n",
            "Epoch 469/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1090 - accuracy: 0.9584 - val_loss: 0.5486 - val_accuracy: 0.8467\n",
            "Epoch 470/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1124 - accuracy: 0.9573 - val_loss: 0.5783 - val_accuracy: 0.8325\n",
            "Epoch 471/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1075 - accuracy: 0.9626 - val_loss: 0.5866 - val_accuracy: 0.8432\n",
            "Epoch 472/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1054 - accuracy: 0.9649 - val_loss: 0.6235 - val_accuracy: 0.8325\n",
            "Epoch 473/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1239 - accuracy: 0.9549 - val_loss: 0.5850 - val_accuracy: 0.8290\n",
            "Epoch 474/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1146 - accuracy: 0.9558 - val_loss: 0.5710 - val_accuracy: 0.8420\n",
            "Epoch 475/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1089 - accuracy: 0.9637 - val_loss: 0.5717 - val_accuracy: 0.8373\n",
            "Epoch 476/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1089 - accuracy: 0.9631 - val_loss: 0.5981 - val_accuracy: 0.8325\n",
            "Epoch 477/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1062 - accuracy: 0.9605 - val_loss: 0.5961 - val_accuracy: 0.8550\n",
            "Epoch 478/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1144 - accuracy: 0.9590 - val_loss: 0.5577 - val_accuracy: 0.8502\n",
            "Epoch 479/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1076 - accuracy: 0.9608 - val_loss: 0.5878 - val_accuracy: 0.8420\n",
            "Epoch 480/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1052 - accuracy: 0.9637 - val_loss: 0.5610 - val_accuracy: 0.8550\n",
            "Epoch 481/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1011 - accuracy: 0.9649 - val_loss: 0.6095 - val_accuracy: 0.8373\n",
            "Epoch 482/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1127 - accuracy: 0.9573 - val_loss: 0.5739 - val_accuracy: 0.8432\n",
            "Epoch 483/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.5386 - val_accuracy: 0.8538\n",
            "Epoch 484/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1037 - accuracy: 0.9640 - val_loss: 0.5954 - val_accuracy: 0.8420\n",
            "Epoch 485/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1098 - accuracy: 0.9599 - val_loss: 0.5675 - val_accuracy: 0.8408\n",
            "Epoch 486/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1054 - accuracy: 0.9629 - val_loss: 0.5642 - val_accuracy: 0.8491\n",
            "Epoch 487/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1094 - accuracy: 0.9623 - val_loss: 0.5530 - val_accuracy: 0.8443\n",
            "Epoch 488/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1025 - accuracy: 0.9682 - val_loss: 0.6030 - val_accuracy: 0.8526\n",
            "Epoch 489/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0981 - accuracy: 0.9623 - val_loss: 0.5766 - val_accuracy: 0.8561\n",
            "Epoch 490/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1100 - accuracy: 0.9605 - val_loss: 0.5589 - val_accuracy: 0.8479\n",
            "Epoch 491/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1012 - accuracy: 0.9661 - val_loss: 0.5499 - val_accuracy: 0.8361\n",
            "Epoch 492/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1025 - accuracy: 0.9655 - val_loss: 0.6106 - val_accuracy: 0.8443\n",
            "Epoch 493/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.5744 - val_accuracy: 0.8373\n",
            "Epoch 494/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1041 - accuracy: 0.9652 - val_loss: 0.6142 - val_accuracy: 0.8420\n",
            "Epoch 495/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1064 - accuracy: 0.9620 - val_loss: 0.6090 - val_accuracy: 0.8396\n",
            "Epoch 496/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1062 - accuracy: 0.9587 - val_loss: 0.5855 - val_accuracy: 0.8491\n",
            "Epoch 497/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.5730 - val_accuracy: 0.8408\n",
            "Epoch 498/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1032 - accuracy: 0.9658 - val_loss: 0.5612 - val_accuracy: 0.8550\n",
            "Epoch 499/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1044 - accuracy: 0.9629 - val_loss: 0.6008 - val_accuracy: 0.8349\n",
            "Epoch 500/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1058 - accuracy: 0.9646 - val_loss: 0.5639 - val_accuracy: 0.8420\n",
            "Epoch 501/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1015 - accuracy: 0.9649 - val_loss: 0.5513 - val_accuracy: 0.8479\n",
            "Epoch 502/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1080 - accuracy: 0.9620 - val_loss: 0.5555 - val_accuracy: 0.8514\n",
            "Epoch 503/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0954 - accuracy: 0.9688 - val_loss: 0.6045 - val_accuracy: 0.8384\n",
            "Epoch 504/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.1039 - accuracy: 0.9623 - val_loss: 0.5517 - val_accuracy: 0.8420\n",
            "Epoch 505/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0977 - accuracy: 0.9643 - val_loss: 0.5941 - val_accuracy: 0.8514\n",
            "Epoch 506/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0988 - accuracy: 0.9664 - val_loss: 0.5683 - val_accuracy: 0.8514\n",
            "Epoch 507/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0979 - accuracy: 0.9673 - val_loss: 0.6113 - val_accuracy: 0.8396\n",
            "Epoch 508/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0926 - accuracy: 0.9661 - val_loss: 0.5692 - val_accuracy: 0.8538\n",
            "Epoch 509/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0924 - accuracy: 0.9699 - val_loss: 0.6103 - val_accuracy: 0.8514\n",
            "Epoch 510/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.6096 - val_accuracy: 0.8349\n",
            "Epoch 511/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0956 - accuracy: 0.9685 - val_loss: 0.5842 - val_accuracy: 0.8479\n",
            "Epoch 512/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0947 - accuracy: 0.9673 - val_loss: 0.6200 - val_accuracy: 0.8479\n",
            "Epoch 513/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0885 - accuracy: 0.9673 - val_loss: 0.6045 - val_accuracy: 0.8467\n",
            "Epoch 514/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0988 - accuracy: 0.9658 - val_loss: 0.5733 - val_accuracy: 0.8420\n",
            "Epoch 515/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0993 - accuracy: 0.9640 - val_loss: 0.5885 - val_accuracy: 0.8443\n",
            "Epoch 516/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0946 - accuracy: 0.9670 - val_loss: 0.5880 - val_accuracy: 0.8491\n",
            "Epoch 517/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0959 - accuracy: 0.9682 - val_loss: 0.6061 - val_accuracy: 0.8396\n",
            "Epoch 518/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0929 - accuracy: 0.9679 - val_loss: 0.5785 - val_accuracy: 0.8561\n",
            "Epoch 519/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0922 - accuracy: 0.9655 - val_loss: 0.6074 - val_accuracy: 0.8491\n",
            "Epoch 520/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0984 - accuracy: 0.9649 - val_loss: 0.6079 - val_accuracy: 0.8479\n",
            "Epoch 521/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0936 - accuracy: 0.9673 - val_loss: 0.5787 - val_accuracy: 0.8585\n",
            "Epoch 522/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0958 - accuracy: 0.9679 - val_loss: 0.6259 - val_accuracy: 0.8337\n",
            "Epoch 523/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.6073 - val_accuracy: 0.8491\n",
            "Epoch 524/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0938 - accuracy: 0.9682 - val_loss: 0.5974 - val_accuracy: 0.8408\n",
            "Epoch 525/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0917 - accuracy: 0.9670 - val_loss: 0.5901 - val_accuracy: 0.8550\n",
            "Epoch 526/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0869 - accuracy: 0.9702 - val_loss: 0.6061 - val_accuracy: 0.8337\n",
            "Epoch 527/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0977 - accuracy: 0.9631 - val_loss: 0.6138 - val_accuracy: 0.8502\n",
            "Epoch 528/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0943 - accuracy: 0.9670 - val_loss: 0.6017 - val_accuracy: 0.8408\n",
            "Epoch 529/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0940 - accuracy: 0.9658 - val_loss: 0.6228 - val_accuracy: 0.8443\n",
            "Epoch 530/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0904 - accuracy: 0.9664 - val_loss: 0.6184 - val_accuracy: 0.8349\n",
            "Epoch 531/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0803 - accuracy: 0.9720 - val_loss: 0.6190 - val_accuracy: 0.8561\n",
            "Epoch 532/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0797 - accuracy: 0.9746 - val_loss: 0.6333 - val_accuracy: 0.8396\n",
            "Epoch 533/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0956 - accuracy: 0.9667 - val_loss: 0.6162 - val_accuracy: 0.8325\n",
            "Epoch 534/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0919 - accuracy: 0.9685 - val_loss: 0.6253 - val_accuracy: 0.8349\n",
            "Epoch 535/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0885 - accuracy: 0.9690 - val_loss: 0.6770 - val_accuracy: 0.8337\n",
            "Epoch 536/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0967 - accuracy: 0.9649 - val_loss: 0.6225 - val_accuracy: 0.8502\n",
            "Epoch 537/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0920 - accuracy: 0.9679 - val_loss: 0.6065 - val_accuracy: 0.8526\n",
            "Epoch 538/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0916 - accuracy: 0.9679 - val_loss: 0.5782 - val_accuracy: 0.8491\n",
            "Epoch 539/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0932 - accuracy: 0.9679 - val_loss: 0.5968 - val_accuracy: 0.8502\n",
            "Epoch 540/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0849 - accuracy: 0.9699 - val_loss: 0.6136 - val_accuracy: 0.8467\n",
            "Epoch 541/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0928 - accuracy: 0.9679 - val_loss: 0.5919 - val_accuracy: 0.8538\n",
            "Epoch 542/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0803 - accuracy: 0.9711 - val_loss: 0.6215 - val_accuracy: 0.8479\n",
            "Epoch 543/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 0.6307 - val_accuracy: 0.8585\n",
            "Epoch 544/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0920 - accuracy: 0.9658 - val_loss: 0.6142 - val_accuracy: 0.8491\n",
            "Epoch 545/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0847 - accuracy: 0.9685 - val_loss: 0.6219 - val_accuracy: 0.8373\n",
            "Epoch 546/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0914 - accuracy: 0.9670 - val_loss: 0.6130 - val_accuracy: 0.8337\n",
            "Epoch 547/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0813 - accuracy: 0.9723 - val_loss: 0.5913 - val_accuracy: 0.8526\n",
            "Epoch 548/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0849 - accuracy: 0.9723 - val_loss: 0.5793 - val_accuracy: 0.8502\n",
            "Epoch 549/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0809 - accuracy: 0.9688 - val_loss: 0.6395 - val_accuracy: 0.8479\n",
            "Epoch 550/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0887 - accuracy: 0.9723 - val_loss: 0.6111 - val_accuracy: 0.8538\n",
            "Epoch 551/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0870 - accuracy: 0.9708 - val_loss: 0.6303 - val_accuracy: 0.8538\n",
            "Epoch 552/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0798 - accuracy: 0.9711 - val_loss: 0.6250 - val_accuracy: 0.8491\n",
            "Epoch 553/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.6283 - val_accuracy: 0.8491\n",
            "Epoch 554/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0805 - accuracy: 0.9723 - val_loss: 0.6166 - val_accuracy: 0.8561\n",
            "Epoch 555/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0839 - accuracy: 0.9699 - val_loss: 0.6197 - val_accuracy: 0.8443\n",
            "Epoch 556/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0858 - accuracy: 0.9723 - val_loss: 0.6152 - val_accuracy: 0.8585\n",
            "Epoch 557/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0826 - accuracy: 0.9693 - val_loss: 0.6688 - val_accuracy: 0.8420\n",
            "Epoch 558/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0762 - accuracy: 0.9729 - val_loss: 0.5753 - val_accuracy: 0.8502\n",
            "Epoch 559/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0747 - accuracy: 0.9744 - val_loss: 0.5882 - val_accuracy: 0.8550\n",
            "Epoch 560/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 0.5981 - val_accuracy: 0.8573\n",
            "Epoch 561/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0853 - accuracy: 0.9688 - val_loss: 0.6019 - val_accuracy: 0.8479\n",
            "Epoch 562/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0874 - accuracy: 0.9726 - val_loss: 0.6020 - val_accuracy: 0.8550\n",
            "Epoch 563/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0790 - accuracy: 0.9741 - val_loss: 0.6285 - val_accuracy: 0.8491\n",
            "Epoch 564/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0822 - accuracy: 0.9711 - val_loss: 0.6449 - val_accuracy: 0.8491\n",
            "Epoch 565/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0699 - accuracy: 0.9761 - val_loss: 0.5998 - val_accuracy: 0.8491\n",
            "Epoch 566/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0811 - accuracy: 0.9702 - val_loss: 0.5975 - val_accuracy: 0.8491\n",
            "Epoch 567/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0800 - accuracy: 0.9729 - val_loss: 0.6387 - val_accuracy: 0.8467\n",
            "Epoch 568/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0800 - accuracy: 0.9720 - val_loss: 0.6272 - val_accuracy: 0.8491\n",
            "Epoch 569/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0848 - accuracy: 0.9735 - val_loss: 0.6328 - val_accuracy: 0.8491\n",
            "Epoch 570/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0721 - accuracy: 0.9741 - val_loss: 0.6071 - val_accuracy: 0.8573\n",
            "Epoch 571/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0751 - accuracy: 0.9735 - val_loss: 0.6207 - val_accuracy: 0.8408\n",
            "Epoch 572/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0746 - accuracy: 0.9729 - val_loss: 0.6596 - val_accuracy: 0.8561\n",
            "Epoch 573/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0828 - accuracy: 0.9720 - val_loss: 0.6274 - val_accuracy: 0.8290\n",
            "Epoch 574/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: 0.6463 - val_accuracy: 0.8373\n",
            "Epoch 575/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0831 - accuracy: 0.9702 - val_loss: 0.6240 - val_accuracy: 0.8455\n",
            "Epoch 576/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0730 - accuracy: 0.9761 - val_loss: 0.6289 - val_accuracy: 0.8514\n",
            "Epoch 577/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.6553 - val_accuracy: 0.8443\n",
            "Epoch 578/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0745 - accuracy: 0.9741 - val_loss: 0.5927 - val_accuracy: 0.8396\n",
            "Epoch 579/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0833 - accuracy: 0.9723 - val_loss: 0.6307 - val_accuracy: 0.8443\n",
            "Epoch 580/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0688 - accuracy: 0.9764 - val_loss: 0.6437 - val_accuracy: 0.8550\n",
            "Epoch 581/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0762 - accuracy: 0.9758 - val_loss: 0.6292 - val_accuracy: 0.8479\n",
            "Epoch 582/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.6369 - val_accuracy: 0.8432\n",
            "Epoch 583/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.6266 - val_accuracy: 0.8467\n",
            "Epoch 584/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0690 - accuracy: 0.9776 - val_loss: 0.6313 - val_accuracy: 0.8561\n",
            "Epoch 585/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0722 - accuracy: 0.9735 - val_loss: 0.6338 - val_accuracy: 0.8491\n",
            "Epoch 586/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0691 - accuracy: 0.9794 - val_loss: 0.6042 - val_accuracy: 0.8585\n",
            "Epoch 587/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0817 - accuracy: 0.9708 - val_loss: 0.6368 - val_accuracy: 0.8420\n",
            "Epoch 588/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0787 - accuracy: 0.9720 - val_loss: 0.6023 - val_accuracy: 0.8479\n",
            "Epoch 589/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.7000 - val_accuracy: 0.8432\n",
            "Epoch 590/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0746 - accuracy: 0.9738 - val_loss: 0.6766 - val_accuracy: 0.8479\n",
            "Epoch 591/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0706 - accuracy: 0.9732 - val_loss: 0.6019 - val_accuracy: 0.8597\n",
            "Epoch 592/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0745 - accuracy: 0.9729 - val_loss: 0.6327 - val_accuracy: 0.8526\n",
            "Epoch 593/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0780 - accuracy: 0.9711 - val_loss: 0.6417 - val_accuracy: 0.8420\n",
            "Epoch 594/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0781 - accuracy: 0.9711 - val_loss: 0.6246 - val_accuracy: 0.8561\n",
            "Epoch 595/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.6306 - val_accuracy: 0.8455\n",
            "Epoch 596/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 0.6301 - val_accuracy: 0.8467\n",
            "Epoch 597/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0709 - accuracy: 0.9788 - val_loss: 0.6747 - val_accuracy: 0.8325\n",
            "Epoch 598/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0701 - accuracy: 0.9755 - val_loss: 0.6619 - val_accuracy: 0.8526\n",
            "Epoch 599/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0750 - accuracy: 0.9738 - val_loss: 0.6299 - val_accuracy: 0.8502\n",
            "Epoch 600/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 0.6360 - val_accuracy: 0.8479\n",
            "Epoch 601/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0775 - accuracy: 0.9744 - val_loss: 0.6085 - val_accuracy: 0.8526\n",
            "Epoch 602/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0708 - accuracy: 0.9770 - val_loss: 0.6380 - val_accuracy: 0.8526\n",
            "Epoch 603/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0689 - accuracy: 0.9764 - val_loss: 0.6594 - val_accuracy: 0.8597\n",
            "Epoch 604/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0642 - accuracy: 0.9794 - val_loss: 0.6370 - val_accuracy: 0.8632\n",
            "Epoch 605/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0660 - accuracy: 0.9764 - val_loss: 0.6667 - val_accuracy: 0.8502\n",
            "Epoch 606/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.6552 - val_accuracy: 0.8479\n",
            "Epoch 607/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.6199 - val_accuracy: 0.8526\n",
            "Epoch 608/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0741 - accuracy: 0.9744 - val_loss: 0.6664 - val_accuracy: 0.8526\n",
            "Epoch 609/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.6491 - val_accuracy: 0.8502\n",
            "Epoch 610/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0597 - accuracy: 0.9829 - val_loss: 0.6710 - val_accuracy: 0.8467\n",
            "Epoch 611/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0760 - accuracy: 0.9741 - val_loss: 0.6676 - val_accuracy: 0.8550\n",
            "Epoch 612/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 0.6503 - val_accuracy: 0.8502\n",
            "Epoch 613/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 0.7000 - val_accuracy: 0.8420\n",
            "Epoch 614/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0646 - accuracy: 0.9770 - val_loss: 0.6496 - val_accuracy: 0.8467\n",
            "Epoch 615/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0715 - accuracy: 0.9746 - val_loss: 0.6636 - val_accuracy: 0.8408\n",
            "Epoch 616/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0689 - accuracy: 0.9746 - val_loss: 0.6351 - val_accuracy: 0.8502\n",
            "Epoch 617/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0678 - accuracy: 0.9761 - val_loss: 0.6306 - val_accuracy: 0.8467\n",
            "Epoch 618/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0638 - accuracy: 0.9758 - val_loss: 0.6650 - val_accuracy: 0.8502\n",
            "Epoch 619/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.6527 - val_accuracy: 0.8432\n",
            "Epoch 620/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0732 - accuracy: 0.9797 - val_loss: 0.6423 - val_accuracy: 0.8467\n",
            "Epoch 621/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0625 - accuracy: 0.9791 - val_loss: 0.6660 - val_accuracy: 0.8491\n",
            "Epoch 622/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0590 - accuracy: 0.9776 - val_loss: 0.6641 - val_accuracy: 0.8514\n",
            "Epoch 623/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0641 - accuracy: 0.9776 - val_loss: 0.6757 - val_accuracy: 0.8538\n",
            "Epoch 624/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0658 - accuracy: 0.9770 - val_loss: 0.6429 - val_accuracy: 0.8561\n",
            "Epoch 625/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.6365 - val_accuracy: 0.8420\n",
            "Epoch 626/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0662 - accuracy: 0.9788 - val_loss: 0.6603 - val_accuracy: 0.8443\n",
            "Epoch 627/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0630 - accuracy: 0.9782 - val_loss: 0.6456 - val_accuracy: 0.8420\n",
            "Epoch 628/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 0.6571 - val_accuracy: 0.8502\n",
            "Epoch 629/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0606 - accuracy: 0.9802 - val_loss: 0.6815 - val_accuracy: 0.8396\n",
            "Epoch 630/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 0.6202 - val_accuracy: 0.8443\n",
            "Epoch 631/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0697 - accuracy: 0.9749 - val_loss: 0.6303 - val_accuracy: 0.8620\n",
            "Epoch 632/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0623 - accuracy: 0.9773 - val_loss: 0.6460 - val_accuracy: 0.8526\n",
            "Epoch 633/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0589 - accuracy: 0.9791 - val_loss: 0.6537 - val_accuracy: 0.8608\n",
            "Epoch 634/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0612 - accuracy: 0.9782 - val_loss: 0.6352 - val_accuracy: 0.8479\n",
            "Epoch 635/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.6580 - val_accuracy: 0.8550\n",
            "Epoch 636/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 0.6742 - val_accuracy: 0.8443\n",
            "Epoch 637/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.6619 - val_accuracy: 0.8550\n",
            "Epoch 638/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.6880 - val_accuracy: 0.8408\n",
            "Epoch 639/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 0.6324 - val_accuracy: 0.8455\n",
            "Epoch 640/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0717 - accuracy: 0.9741 - val_loss: 0.6591 - val_accuracy: 0.8384\n",
            "Epoch 641/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0625 - accuracy: 0.9791 - val_loss: 0.6467 - val_accuracy: 0.8373\n",
            "Epoch 642/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0668 - accuracy: 0.9785 - val_loss: 0.7028 - val_accuracy: 0.8396\n",
            "Epoch 643/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.6508 - val_accuracy: 0.8396\n",
            "Epoch 644/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.6796 - val_accuracy: 0.8384\n",
            "Epoch 645/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.6467 - val_accuracy: 0.8538\n",
            "Epoch 646/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0542 - accuracy: 0.9805 - val_loss: 0.6780 - val_accuracy: 0.8467\n",
            "Epoch 647/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: 0.6602 - val_accuracy: 0.8467\n",
            "Epoch 648/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0556 - accuracy: 0.9782 - val_loss: 0.6564 - val_accuracy: 0.8491\n",
            "Epoch 649/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0589 - accuracy: 0.9770 - val_loss: 0.6772 - val_accuracy: 0.8550\n",
            "Epoch 650/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0588 - accuracy: 0.9791 - val_loss: 0.6518 - val_accuracy: 0.8432\n",
            "Epoch 651/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.6816 - val_accuracy: 0.8408\n",
            "Epoch 652/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 0.6412 - val_accuracy: 0.8420\n",
            "Epoch 653/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0532 - accuracy: 0.9829 - val_loss: 0.6724 - val_accuracy: 0.8443\n",
            "Epoch 654/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0548 - accuracy: 0.9794 - val_loss: 0.6635 - val_accuracy: 0.8420\n",
            "Epoch 655/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0695 - accuracy: 0.9752 - val_loss: 0.6479 - val_accuracy: 0.8455\n",
            "Epoch 656/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0594 - accuracy: 0.9797 - val_loss: 0.7419 - val_accuracy: 0.8455\n",
            "Epoch 657/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0670 - accuracy: 0.9773 - val_loss: 0.6498 - val_accuracy: 0.8573\n",
            "Epoch 658/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0529 - accuracy: 0.9776 - val_loss: 0.7366 - val_accuracy: 0.8502\n",
            "Epoch 659/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.7381 - val_accuracy: 0.8384\n",
            "Epoch 660/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0521 - accuracy: 0.9838 - val_loss: 0.7127 - val_accuracy: 0.8349\n",
            "Epoch 661/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0595 - accuracy: 0.9808 - val_loss: 0.6610 - val_accuracy: 0.8561\n",
            "Epoch 662/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 0.6805 - val_accuracy: 0.8420\n",
            "Epoch 663/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0488 - accuracy: 0.9829 - val_loss: 0.7027 - val_accuracy: 0.8443\n",
            "Epoch 664/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.6606 - val_accuracy: 0.8573\n",
            "Epoch 665/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0583 - accuracy: 0.9776 - val_loss: 0.6463 - val_accuracy: 0.8373\n",
            "Epoch 666/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.6569 - val_accuracy: 0.8538\n",
            "Epoch 667/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9820 - val_loss: 0.6799 - val_accuracy: 0.8491\n",
            "Epoch 668/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.7142 - val_accuracy: 0.8384\n",
            "Epoch 669/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9802 - val_loss: 0.7212 - val_accuracy: 0.8455\n",
            "Epoch 670/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0579 - accuracy: 0.9800 - val_loss: 0.6681 - val_accuracy: 0.8408\n",
            "Epoch 671/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.6692 - val_accuracy: 0.8420\n",
            "Epoch 672/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.7235 - val_accuracy: 0.8467\n",
            "Epoch 673/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.7180 - val_accuracy: 0.8550\n",
            "Epoch 674/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.6672 - val_accuracy: 0.8538\n",
            "Epoch 675/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.6666 - val_accuracy: 0.8632\n",
            "Epoch 676/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.6682 - val_accuracy: 0.8455\n",
            "Epoch 677/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0589 - accuracy: 0.9788 - val_loss: 0.6870 - val_accuracy: 0.8514\n",
            "Epoch 678/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0535 - accuracy: 0.9800 - val_loss: 0.6676 - val_accuracy: 0.8573\n",
            "Epoch 679/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.6918 - val_accuracy: 0.8514\n",
            "Epoch 680/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0608 - accuracy: 0.9782 - val_loss: 0.7304 - val_accuracy: 0.8467\n",
            "Epoch 681/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.7390 - val_accuracy: 0.8467\n",
            "Epoch 682/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0610 - accuracy: 0.9773 - val_loss: 0.6830 - val_accuracy: 0.8420\n",
            "Epoch 683/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0586 - accuracy: 0.9794 - val_loss: 0.6944 - val_accuracy: 0.8526\n",
            "Epoch 684/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.6729 - val_accuracy: 0.8550\n",
            "Epoch 685/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.7214 - val_accuracy: 0.8443\n",
            "Epoch 686/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.7048 - val_accuracy: 0.8491\n",
            "Epoch 687/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 0.7005 - val_accuracy: 0.8467\n",
            "Epoch 688/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.6871 - val_accuracy: 0.8538\n",
            "Epoch 689/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.6828 - val_accuracy: 0.8514\n",
            "Epoch 690/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0482 - accuracy: 0.9826 - val_loss: 0.7054 - val_accuracy: 0.8526\n",
            "Epoch 691/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.7107 - val_accuracy: 0.8514\n",
            "Epoch 692/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0562 - accuracy: 0.9788 - val_loss: 0.7112 - val_accuracy: 0.8561\n",
            "Epoch 693/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.7176 - val_accuracy: 0.8526\n",
            "Epoch 694/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0531 - accuracy: 0.9797 - val_loss: 0.7065 - val_accuracy: 0.8526\n",
            "Epoch 695/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0488 - accuracy: 0.9870 - val_loss: 0.7394 - val_accuracy: 0.8467\n",
            "Epoch 696/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.6889 - val_accuracy: 0.8479\n",
            "Epoch 697/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.6889 - val_accuracy: 0.8514\n",
            "Epoch 698/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: 0.6982 - val_accuracy: 0.8550\n",
            "Epoch 699/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.6826 - val_accuracy: 0.8538\n",
            "Epoch 700/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 0.6826 - val_accuracy: 0.8502\n",
            "Epoch 701/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.6851 - val_accuracy: 0.8538\n",
            "Epoch 702/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0556 - accuracy: 0.9779 - val_loss: 0.7032 - val_accuracy: 0.8597\n",
            "Epoch 703/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0551 - accuracy: 0.9853 - val_loss: 0.6878 - val_accuracy: 0.8597\n",
            "Epoch 704/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0559 - accuracy: 0.9805 - val_loss: 0.7052 - val_accuracy: 0.8361\n",
            "Epoch 705/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.6782 - val_accuracy: 0.8608\n",
            "Epoch 706/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.7192 - val_accuracy: 0.8502\n",
            "Epoch 707/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.7370 - val_accuracy: 0.8538\n",
            "Epoch 708/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0537 - accuracy: 0.9808 - val_loss: 0.7210 - val_accuracy: 0.8585\n",
            "Epoch 709/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.7317 - val_accuracy: 0.8538\n",
            "Epoch 710/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0475 - accuracy: 0.9858 - val_loss: 0.7296 - val_accuracy: 0.8514\n",
            "Epoch 711/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.7414 - val_accuracy: 0.8502\n",
            "Epoch 712/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.7239 - val_accuracy: 0.8538\n",
            "Epoch 713/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0504 - accuracy: 0.9805 - val_loss: 0.7159 - val_accuracy: 0.8573\n",
            "Epoch 714/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0468 - accuracy: 0.9823 - val_loss: 0.7255 - val_accuracy: 0.8455\n",
            "Epoch 715/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.6697 - val_accuracy: 0.8597\n",
            "Epoch 716/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 0.7051 - val_accuracy: 0.8491\n",
            "Epoch 717/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.7226 - val_accuracy: 0.8526\n",
            "Epoch 718/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.7770 - val_accuracy: 0.8408\n",
            "Epoch 719/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.7877 - val_accuracy: 0.8384\n",
            "Epoch 720/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.7161 - val_accuracy: 0.8491\n",
            "Epoch 721/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.7896 - val_accuracy: 0.8514\n",
            "Epoch 722/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 0.9820 - val_loss: 0.7616 - val_accuracy: 0.8420\n",
            "Epoch 723/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.7548 - val_accuracy: 0.8561\n",
            "Epoch 724/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.7406 - val_accuracy: 0.8373\n",
            "Epoch 725/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.7255 - val_accuracy: 0.8502\n",
            "Epoch 726/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.7811 - val_accuracy: 0.8443\n",
            "Epoch 727/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0391 - accuracy: 0.9853 - val_loss: 0.7413 - val_accuracy: 0.8491\n",
            "Epoch 728/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 0.7280 - val_accuracy: 0.8502\n",
            "Epoch 729/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.7340 - val_accuracy: 0.8526\n",
            "Epoch 730/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.7139 - val_accuracy: 0.8573\n",
            "Epoch 731/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0462 - accuracy: 0.9850 - val_loss: 0.7297 - val_accuracy: 0.8467\n",
            "Epoch 732/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 0.7233 - val_accuracy: 0.8585\n",
            "Epoch 733/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 0.7179 - val_accuracy: 0.8491\n",
            "Epoch 734/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.6796 - val_accuracy: 0.8526\n",
            "Epoch 735/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.7553 - val_accuracy: 0.8585\n",
            "Epoch 736/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0479 - accuracy: 0.9820 - val_loss: 0.7239 - val_accuracy: 0.8455\n",
            "Epoch 737/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.7042 - val_accuracy: 0.8467\n",
            "Epoch 738/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.7352 - val_accuracy: 0.8420\n",
            "Epoch 739/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 0.7289 - val_accuracy: 0.8443\n",
            "Epoch 740/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.6919 - val_accuracy: 0.8550\n",
            "Epoch 741/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.7201 - val_accuracy: 0.8491\n",
            "Epoch 742/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 0.7488 - val_accuracy: 0.8526\n",
            "Epoch 743/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.8132 - val_accuracy: 0.8255\n",
            "Epoch 744/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.7645 - val_accuracy: 0.8455\n",
            "Epoch 745/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.7238 - val_accuracy: 0.8514\n",
            "Epoch 746/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 0.7528 - val_accuracy: 0.8491\n",
            "Epoch 747/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.6960 - val_accuracy: 0.8538\n",
            "Epoch 748/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 0.7406 - val_accuracy: 0.8467\n",
            "Epoch 749/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.7245 - val_accuracy: 0.8514\n",
            "Epoch 750/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.7175 - val_accuracy: 0.8632\n",
            "Epoch 751/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.7314 - val_accuracy: 0.8561\n",
            "Epoch 752/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.7379 - val_accuracy: 0.8514\n",
            "Epoch 753/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0472 - accuracy: 0.9832 - val_loss: 0.7635 - val_accuracy: 0.8455\n",
            "Epoch 754/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.7568 - val_accuracy: 0.8420\n",
            "Epoch 755/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.7195 - val_accuracy: 0.8526\n",
            "Epoch 756/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 0.7421 - val_accuracy: 0.8526\n",
            "Epoch 757/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.7404 - val_accuracy: 0.8538\n",
            "Epoch 758/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0503 - accuracy: 0.9826 - val_loss: 0.7814 - val_accuracy: 0.8349\n",
            "Epoch 759/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0412 - accuracy: 0.9847 - val_loss: 0.7452 - val_accuracy: 0.8455\n",
            "Epoch 760/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0418 - accuracy: 0.9853 - val_loss: 0.7306 - val_accuracy: 0.8550\n",
            "Epoch 761/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0405 - accuracy: 0.9856 - val_loss: 0.7492 - val_accuracy: 0.8538\n",
            "Epoch 762/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.8196 - val_accuracy: 0.8361\n",
            "Epoch 763/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 0.7443 - val_accuracy: 0.8455\n",
            "Epoch 764/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0545 - accuracy: 0.9814 - val_loss: 0.6903 - val_accuracy: 0.8514\n",
            "Epoch 765/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.8275 - val_accuracy: 0.8455\n",
            "Epoch 766/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0434 - accuracy: 0.9879 - val_loss: 0.7624 - val_accuracy: 0.8585\n",
            "Epoch 767/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.7190 - val_accuracy: 0.8550\n",
            "Epoch 768/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.7162 - val_accuracy: 0.8585\n",
            "Epoch 769/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0391 - accuracy: 0.9858 - val_loss: 0.7570 - val_accuracy: 0.8467\n",
            "Epoch 770/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.7386 - val_accuracy: 0.8573\n",
            "Epoch 771/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 0.7589 - val_accuracy: 0.8608\n",
            "Epoch 772/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.7647 - val_accuracy: 0.8585\n",
            "Epoch 773/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.7993 - val_accuracy: 0.8455\n",
            "Epoch 774/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0452 - accuracy: 0.9829 - val_loss: 0.7802 - val_accuracy: 0.8384\n",
            "Epoch 775/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 0.7620 - val_accuracy: 0.8526\n",
            "Epoch 776/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.7721 - val_accuracy: 0.8420\n",
            "Epoch 777/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0407 - accuracy: 0.9856 - val_loss: 0.7103 - val_accuracy: 0.8396\n",
            "Epoch 778/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0441 - accuracy: 0.9856 - val_loss: 0.7652 - val_accuracy: 0.8373\n",
            "Epoch 779/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.7438 - val_accuracy: 0.8538\n",
            "Epoch 780/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0394 - accuracy: 0.9847 - val_loss: 0.7340 - val_accuracy: 0.8479\n",
            "Epoch 781/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0412 - accuracy: 0.9838 - val_loss: 0.7249 - val_accuracy: 0.8514\n",
            "Epoch 782/1300\n",
            "212/212 [==============================] - 2s 10ms/step - loss: 0.0434 - accuracy: 0.9879 - val_loss: 0.7332 - val_accuracy: 0.8550\n",
            "Epoch 783/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0407 - accuracy: 0.9858 - val_loss: 0.7586 - val_accuracy: 0.8455\n",
            "Epoch 784/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.7149 - val_accuracy: 0.8573\n",
            "Epoch 785/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0389 - accuracy: 0.9853 - val_loss: 0.7626 - val_accuracy: 0.8479\n",
            "Epoch 786/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0415 - accuracy: 0.9844 - val_loss: 0.7334 - val_accuracy: 0.8432\n",
            "Epoch 787/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.7293 - val_accuracy: 0.8491\n",
            "Epoch 788/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 0.7297 - val_accuracy: 0.8491\n",
            "Epoch 789/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.7045 - val_accuracy: 0.8550\n",
            "Epoch 790/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.7219 - val_accuracy: 0.8514\n",
            "Epoch 791/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0467 - accuracy: 0.9864 - val_loss: 0.7172 - val_accuracy: 0.8538\n",
            "Epoch 792/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.7598 - val_accuracy: 0.8538\n",
            "Epoch 793/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.7482 - val_accuracy: 0.8443\n",
            "Epoch 794/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.7506 - val_accuracy: 0.8502\n",
            "Epoch 795/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0354 - accuracy: 0.9888 - val_loss: 0.8240 - val_accuracy: 0.8491\n",
            "Epoch 796/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.7210 - val_accuracy: 0.8550\n",
            "Epoch 797/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.8337 - val_accuracy: 0.8479\n",
            "Epoch 798/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0372 - accuracy: 0.9861 - val_loss: 0.7237 - val_accuracy: 0.8491\n",
            "Epoch 799/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.7761 - val_accuracy: 0.8479\n",
            "Epoch 800/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0382 - accuracy: 0.9891 - val_loss: 0.7645 - val_accuracy: 0.8514\n",
            "Epoch 801/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0513 - accuracy: 0.9856 - val_loss: 0.7534 - val_accuracy: 0.8432\n",
            "Epoch 802/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0374 - accuracy: 0.9858 - val_loss: 0.7820 - val_accuracy: 0.8502\n",
            "Epoch 803/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 0.7626 - val_accuracy: 0.8597\n",
            "Epoch 804/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.7370 - val_accuracy: 0.8561\n",
            "Epoch 805/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.8071 - val_accuracy: 0.8467\n",
            "Epoch 806/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 0.8384 - val_accuracy: 0.8443\n",
            "Epoch 807/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.7847 - val_accuracy: 0.8467\n",
            "Epoch 808/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.7415 - val_accuracy: 0.8573\n",
            "Epoch 809/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.7211 - val_accuracy: 0.8573\n",
            "Epoch 810/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.7435 - val_accuracy: 0.8550\n",
            "Epoch 811/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 0.8432 - val_accuracy: 0.8408\n",
            "Epoch 812/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.7815 - val_accuracy: 0.8550\n",
            "Epoch 813/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.8018 - val_accuracy: 0.8538\n",
            "Epoch 814/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0387 - accuracy: 0.9853 - val_loss: 0.7686 - val_accuracy: 0.8479\n",
            "Epoch 815/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 0.7227 - val_accuracy: 0.8502\n",
            "Epoch 816/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.8617 - val_accuracy: 0.8467\n",
            "Epoch 817/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.7280 - val_accuracy: 0.8561\n",
            "Epoch 818/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0382 - accuracy: 0.9847 - val_loss: 0.8111 - val_accuracy: 0.8455\n",
            "Epoch 819/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.8023 - val_accuracy: 0.8526\n",
            "Epoch 820/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.7974 - val_accuracy: 0.8514\n",
            "Epoch 821/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7845 - val_accuracy: 0.8550\n",
            "Epoch 822/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.8404 - val_accuracy: 0.8550\n",
            "Epoch 823/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.8064 - val_accuracy: 0.8502\n",
            "Epoch 824/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 0.7479 - val_accuracy: 0.8550\n",
            "Epoch 825/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 0.7570 - val_accuracy: 0.8443\n",
            "Epoch 826/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.7675 - val_accuracy: 0.8585\n",
            "Epoch 827/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.7798 - val_accuracy: 0.8573\n",
            "Epoch 828/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.8245 - val_accuracy: 0.8420\n",
            "Epoch 829/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.7824 - val_accuracy: 0.8479\n",
            "Epoch 830/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 0.8458 - val_accuracy: 0.8479\n",
            "Epoch 831/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.7815 - val_accuracy: 0.8502\n",
            "Epoch 832/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0328 - accuracy: 0.9858 - val_loss: 0.8013 - val_accuracy: 0.8526\n",
            "Epoch 833/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0402 - accuracy: 0.9858 - val_loss: 0.8036 - val_accuracy: 0.8502\n",
            "Epoch 834/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0364 - accuracy: 0.9870 - val_loss: 0.7719 - val_accuracy: 0.8491\n",
            "Epoch 835/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.8529 - val_accuracy: 0.8361\n",
            "Epoch 836/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.7527 - val_accuracy: 0.8620\n",
            "Epoch 837/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.7671 - val_accuracy: 0.8573\n",
            "Epoch 838/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.7755 - val_accuracy: 0.8467\n",
            "Epoch 839/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.8395 - val_accuracy: 0.8620\n",
            "Epoch 840/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.8847 - val_accuracy: 0.8443\n",
            "Epoch 841/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 0.8131 - val_accuracy: 0.8502\n",
            "Epoch 842/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.9201 - val_accuracy: 0.8361\n",
            "Epoch 843/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.8167 - val_accuracy: 0.8514\n",
            "Epoch 844/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.9207 - val_accuracy: 0.8502\n",
            "Epoch 845/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.8451 - val_accuracy: 0.8384\n",
            "Epoch 846/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.7537 - val_accuracy: 0.8514\n",
            "Epoch 847/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0370 - accuracy: 0.9850 - val_loss: 0.7894 - val_accuracy: 0.8514\n",
            "Epoch 848/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.8145 - val_accuracy: 0.8538\n",
            "Epoch 849/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.8558 - val_accuracy: 0.8467\n",
            "Epoch 850/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.8288 - val_accuracy: 0.8561\n",
            "Epoch 851/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0355 - accuracy: 0.9873 - val_loss: 0.7952 - val_accuracy: 0.8608\n",
            "Epoch 852/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.7709 - val_accuracy: 0.8644\n",
            "Epoch 853/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.8077 - val_accuracy: 0.8632\n",
            "Epoch 854/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0396 - accuracy: 0.9861 - val_loss: 0.7917 - val_accuracy: 0.8597\n",
            "Epoch 855/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.7870 - val_accuracy: 0.8561\n",
            "Epoch 856/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.8032 - val_accuracy: 0.8573\n",
            "Epoch 857/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.8576 - val_accuracy: 0.8491\n",
            "Epoch 858/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.8142 - val_accuracy: 0.8432\n",
            "Epoch 859/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0323 - accuracy: 0.9917 - val_loss: 0.8440 - val_accuracy: 0.8538\n",
            "Epoch 860/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.8032 - val_accuracy: 0.8479\n",
            "Epoch 861/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.9516 - val_accuracy: 0.8479\n",
            "Epoch 862/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.8400 - val_accuracy: 0.8585\n",
            "Epoch 863/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0287 - accuracy: 0.9876 - val_loss: 0.8247 - val_accuracy: 0.8538\n",
            "Epoch 864/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.8485 - val_accuracy: 0.8396\n",
            "Epoch 865/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.8132 - val_accuracy: 0.8585\n",
            "Epoch 866/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.8194 - val_accuracy: 0.8491\n",
            "Epoch 867/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.8575 - val_accuracy: 0.8491\n",
            "Epoch 868/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.8179 - val_accuracy: 0.8585\n",
            "Epoch 869/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.8396 - val_accuracy: 0.8361\n",
            "Epoch 870/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.7385 - val_accuracy: 0.8526\n",
            "Epoch 871/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.7507 - val_accuracy: 0.8479\n",
            "Epoch 872/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0294 - accuracy: 0.9894 - val_loss: 0.8492 - val_accuracy: 0.8573\n",
            "Epoch 873/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.7629 - val_accuracy: 0.8432\n",
            "Epoch 874/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 0.7525 - val_accuracy: 0.8644\n",
            "Epoch 875/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.7957 - val_accuracy: 0.8538\n",
            "Epoch 876/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0430 - accuracy: 0.9847 - val_loss: 0.8230 - val_accuracy: 0.8502\n",
            "Epoch 877/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.8717 - val_accuracy: 0.8337\n",
            "Epoch 878/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.8179 - val_accuracy: 0.8538\n",
            "Epoch 879/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 0.8233 - val_accuracy: 0.8514\n",
            "Epoch 880/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0348 - accuracy: 0.9867 - val_loss: 0.7465 - val_accuracy: 0.8573\n",
            "Epoch 881/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 0.7933 - val_accuracy: 0.8550\n",
            "Epoch 882/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.7555 - val_accuracy: 0.8550\n",
            "Epoch 883/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.8189 - val_accuracy: 0.8502\n",
            "Epoch 884/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.8694 - val_accuracy: 0.8396\n",
            "Epoch 885/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.7410 - val_accuracy: 0.8526\n",
            "Epoch 886/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.7947 - val_accuracy: 0.8632\n",
            "Epoch 887/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.7877 - val_accuracy: 0.8550\n",
            "Epoch 888/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.8110 - val_accuracy: 0.8514\n",
            "Epoch 889/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.7984 - val_accuracy: 0.8561\n",
            "Epoch 890/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.8488 - val_accuracy: 0.8550\n",
            "Epoch 891/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.7933 - val_accuracy: 0.8632\n",
            "Epoch 892/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.8391 - val_accuracy: 0.8373\n",
            "Epoch 893/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.8782 - val_accuracy: 0.8526\n",
            "Epoch 894/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.8145 - val_accuracy: 0.8455\n",
            "Epoch 895/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.9338 - val_accuracy: 0.8479\n",
            "Epoch 896/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0313 - accuracy: 0.9894 - val_loss: 0.8011 - val_accuracy: 0.8538\n",
            "Epoch 897/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.8289 - val_accuracy: 0.8384\n",
            "Epoch 898/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.8450 - val_accuracy: 0.8491\n",
            "Epoch 899/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.8458 - val_accuracy: 0.8597\n",
            "Epoch 900/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.8481 - val_accuracy: 0.8526\n",
            "Epoch 901/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0290 - accuracy: 0.9888 - val_loss: 0.8391 - val_accuracy: 0.8538\n",
            "Epoch 902/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.7841 - val_accuracy: 0.8502\n",
            "Epoch 903/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.8145 - val_accuracy: 0.8597\n",
            "Epoch 904/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.8720 - val_accuracy: 0.8479\n",
            "Epoch 905/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.8655 - val_accuracy: 0.8479\n",
            "Epoch 906/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.8483 - val_accuracy: 0.8573\n",
            "Epoch 907/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 0.9912 - val_accuracy: 0.8502\n",
            "Epoch 908/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.8661 - val_accuracy: 0.8455\n",
            "Epoch 909/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.8654 - val_accuracy: 0.8502\n",
            "Epoch 910/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.8394 - val_accuracy: 0.8573\n",
            "Epoch 911/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0371 - accuracy: 0.9853 - val_loss: 0.8505 - val_accuracy: 0.8443\n",
            "Epoch 912/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0342 - accuracy: 0.9861 - val_loss: 0.8252 - val_accuracy: 0.8608\n",
            "Epoch 913/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0345 - accuracy: 0.9876 - val_loss: 0.8413 - val_accuracy: 0.8561\n",
            "Epoch 914/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.8296 - val_accuracy: 0.8550\n",
            "Epoch 915/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.8234 - val_accuracy: 0.8384\n",
            "Epoch 916/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0326 - accuracy: 0.9858 - val_loss: 0.8287 - val_accuracy: 0.8455\n",
            "Epoch 917/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.8485 - val_accuracy: 0.8585\n",
            "Epoch 918/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0375 - accuracy: 0.9894 - val_loss: 0.8138 - val_accuracy: 0.8597\n",
            "Epoch 919/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0382 - accuracy: 0.9858 - val_loss: 0.8045 - val_accuracy: 0.8585\n",
            "Epoch 920/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.8584 - val_accuracy: 0.8514\n",
            "Epoch 921/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.9079 - val_accuracy: 0.8432\n",
            "Epoch 922/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.8992 - val_accuracy: 0.8620\n",
            "Epoch 923/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.8549 - val_accuracy: 0.8467\n",
            "Epoch 924/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.8827 - val_accuracy: 0.8550\n",
            "Epoch 925/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.8347 - val_accuracy: 0.8432\n",
            "Epoch 926/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0291 - accuracy: 0.9891 - val_loss: 0.8459 - val_accuracy: 0.8491\n",
            "Epoch 927/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.8561 - val_accuracy: 0.8455\n",
            "Epoch 928/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.8405 - val_accuracy: 0.8597\n",
            "Epoch 929/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.8129 - val_accuracy: 0.8514\n",
            "Epoch 930/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0284 - accuracy: 0.9885 - val_loss: 0.8543 - val_accuracy: 0.8432\n",
            "Epoch 931/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.8501 - val_accuracy: 0.8443\n",
            "Epoch 932/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.8445 - val_accuracy: 0.8526\n",
            "Epoch 933/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.9013 - val_accuracy: 0.8467\n",
            "Epoch 934/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.7916 - val_accuracy: 0.8573\n",
            "Epoch 935/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.8151 - val_accuracy: 0.8561\n",
            "Epoch 936/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.8493 - val_accuracy: 0.8455\n",
            "Epoch 937/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.8200 - val_accuracy: 0.8526\n",
            "Epoch 938/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9181 - val_accuracy: 0.8538\n",
            "Epoch 939/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.8170 - val_accuracy: 0.8644\n",
            "Epoch 940/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.8340 - val_accuracy: 0.8561\n",
            "Epoch 941/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0216 - accuracy: 0.9917 - val_loss: 0.8237 - val_accuracy: 0.8632\n",
            "Epoch 942/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.8799 - val_accuracy: 0.8526\n",
            "Epoch 943/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.8577 - val_accuracy: 0.8526\n",
            "Epoch 944/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 0.8417 - val_accuracy: 0.8526\n",
            "Epoch 945/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.8635 - val_accuracy: 0.8573\n",
            "Epoch 946/1300\n",
            "212/212 [==============================] - 2s 11ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.8654 - val_accuracy: 0.8420\n",
            "Epoch 947/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.8124 - val_accuracy: 0.8585\n",
            "Epoch 948/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.8331 - val_accuracy: 0.8585\n",
            "Epoch 949/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.8839 - val_accuracy: 0.8443\n",
            "Epoch 950/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.8742 - val_accuracy: 0.8432\n",
            "Epoch 951/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0352 - accuracy: 0.9903 - val_loss: 0.8581 - val_accuracy: 0.8502\n",
            "Epoch 952/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.8999 - val_accuracy: 0.8396\n",
            "Epoch 953/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.8128 - val_accuracy: 0.8608\n",
            "Epoch 954/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.9019 - val_accuracy: 0.8491\n",
            "Epoch 955/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.9356 - val_accuracy: 0.8373\n",
            "Epoch 956/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0264 - accuracy: 0.9894 - val_loss: 0.8906 - val_accuracy: 0.8349\n",
            "Epoch 957/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.8559 - val_accuracy: 0.8561\n",
            "Epoch 958/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.8863 - val_accuracy: 0.8538\n",
            "Epoch 959/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.8966 - val_accuracy: 0.8573\n",
            "Epoch 960/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 0.8576 - val_accuracy: 0.8526\n",
            "Epoch 961/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.8682 - val_accuracy: 0.8550\n",
            "Epoch 962/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.8214 - val_accuracy: 0.8526\n",
            "Epoch 963/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.8452 - val_accuracy: 0.8479\n",
            "Epoch 964/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.8523 - val_accuracy: 0.8408\n",
            "Epoch 965/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.8515 - val_accuracy: 0.8408\n",
            "Epoch 966/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.9665 - val_accuracy: 0.8396\n",
            "Epoch 967/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.8494 - val_accuracy: 0.8408\n",
            "Epoch 968/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.8588 - val_accuracy: 0.8502\n",
            "Epoch 969/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.8527 - val_accuracy: 0.8514\n",
            "Epoch 970/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.8524 - val_accuracy: 0.8514\n",
            "Epoch 971/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.8764 - val_accuracy: 0.8491\n",
            "Epoch 972/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.8436 - val_accuracy: 0.8632\n",
            "Epoch 973/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.9010 - val_accuracy: 0.8550\n",
            "Epoch 974/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.8383 - val_accuracy: 0.8585\n",
            "Epoch 975/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.8586 - val_accuracy: 0.8526\n",
            "Epoch 976/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 0.9392 - val_accuracy: 0.8550\n",
            "Epoch 977/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.8768 - val_accuracy: 0.8597\n",
            "Epoch 978/1300\n",
            "212/212 [==============================] - 3s 15ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.8631 - val_accuracy: 0.8479\n",
            "Epoch 979/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.9358 - val_accuracy: 0.8491\n",
            "Epoch 980/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.8547 - val_accuracy: 0.8432\n",
            "Epoch 981/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 0.8549 - val_accuracy: 0.8620\n",
            "Epoch 982/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.9215 - val_accuracy: 0.8502\n",
            "Epoch 983/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.9706 - val_accuracy: 0.8396\n",
            "Epoch 984/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0286 - accuracy: 0.9894 - val_loss: 0.8840 - val_accuracy: 0.8561\n",
            "Epoch 985/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.8221 - val_accuracy: 0.8632\n",
            "Epoch 986/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 0.9115 - val_accuracy: 0.8550\n",
            "Epoch 987/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.8313 - val_accuracy: 0.8561\n",
            "Epoch 988/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.8691 - val_accuracy: 0.8632\n",
            "Epoch 989/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.8430 - val_accuracy: 0.8620\n",
            "Epoch 990/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.8299 - val_accuracy: 0.8644\n",
            "Epoch 991/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.8189 - val_accuracy: 0.8561\n",
            "Epoch 992/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.8985 - val_accuracy: 0.8538\n",
            "Epoch 993/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.9189 - val_accuracy: 0.8550\n",
            "Epoch 994/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.9980 - val_accuracy: 0.8514\n",
            "Epoch 995/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.8532 - val_accuracy: 0.8514\n",
            "Epoch 996/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.9277 - val_accuracy: 0.8443\n",
            "Epoch 997/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.8854 - val_accuracy: 0.8644\n",
            "Epoch 998/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.8631 - val_accuracy: 0.8597\n",
            "Epoch 999/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.8970 - val_accuracy: 0.8526\n",
            "Epoch 1000/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.8325 - val_accuracy: 0.8550\n",
            "Epoch 1001/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.8704 - val_accuracy: 0.8514\n",
            "Epoch 1002/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.8711 - val_accuracy: 0.8502\n",
            "Epoch 1003/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0168 - accuracy: 0.9935 - val_loss: 0.9133 - val_accuracy: 0.8550\n",
            "Epoch 1004/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.9077 - val_accuracy: 0.8538\n",
            "Epoch 1005/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.8637 - val_accuracy: 0.8526\n",
            "Epoch 1006/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0260 - accuracy: 0.9891 - val_loss: 0.8821 - val_accuracy: 0.8479\n",
            "Epoch 1007/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0295 - accuracy: 0.9885 - val_loss: 0.8543 - val_accuracy: 0.8491\n",
            "Epoch 1008/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0298 - accuracy: 0.9897 - val_loss: 0.9675 - val_accuracy: 0.8373\n",
            "Epoch 1009/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.9518 - val_accuracy: 0.8526\n",
            "Epoch 1010/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.9148 - val_accuracy: 0.8502\n",
            "Epoch 1011/1300\n",
            "212/212 [==============================] - 3s 15ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.8738 - val_accuracy: 0.8550\n",
            "Epoch 1012/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.8833 - val_accuracy: 0.8479\n",
            "Epoch 1013/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.8783 - val_accuracy: 0.8349\n",
            "Epoch 1014/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.9576 - val_accuracy: 0.8538\n",
            "Epoch 1015/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.8819 - val_accuracy: 0.8455\n",
            "Epoch 1016/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.9444 - val_accuracy: 0.8443\n",
            "Epoch 1017/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.8937 - val_accuracy: 0.8526\n",
            "Epoch 1018/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0292 - accuracy: 0.9885 - val_loss: 1.0194 - val_accuracy: 0.8538\n",
            "Epoch 1019/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.8350 - val_accuracy: 0.8597\n",
            "Epoch 1020/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.8485 - val_accuracy: 0.8561\n",
            "Epoch 1021/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.8704 - val_accuracy: 0.8502\n",
            "Epoch 1022/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0258 - accuracy: 0.9897 - val_loss: 0.9107 - val_accuracy: 0.8597\n",
            "Epoch 1023/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.9336 - val_accuracy: 0.8538\n",
            "Epoch 1024/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.8640 - val_accuracy: 0.8585\n",
            "Epoch 1025/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.8833 - val_accuracy: 0.8479\n",
            "Epoch 1026/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9243 - val_accuracy: 0.8550\n",
            "Epoch 1027/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.9082 - val_accuracy: 0.8491\n",
            "Epoch 1028/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.9402 - val_accuracy: 0.8455\n",
            "Epoch 1029/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0225 - accuracy: 0.9906 - val_loss: 0.9358 - val_accuracy: 0.8573\n",
            "Epoch 1030/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.9335 - val_accuracy: 0.8491\n",
            "Epoch 1031/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.9771 - val_accuracy: 0.8432\n",
            "Epoch 1032/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.9171 - val_accuracy: 0.8420\n",
            "Epoch 1033/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0256 - accuracy: 0.9897 - val_loss: 0.9175 - val_accuracy: 0.8597\n",
            "Epoch 1034/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.8776 - val_accuracy: 0.8455\n",
            "Epoch 1035/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.9139 - val_accuracy: 0.8538\n",
            "Epoch 1036/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.9046 - val_accuracy: 0.8573\n",
            "Epoch 1037/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.9514 - val_accuracy: 0.8550\n",
            "Epoch 1038/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.9244 - val_accuracy: 0.8502\n",
            "Epoch 1039/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.8844 - val_accuracy: 0.8632\n",
            "Epoch 1040/1300\n",
            "212/212 [==============================] - 2s 12ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.9647 - val_accuracy: 0.8420\n",
            "Epoch 1041/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.8759 - val_accuracy: 0.8479\n",
            "Epoch 1042/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.9816 - val_accuracy: 0.8538\n",
            "Epoch 1043/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.9077 - val_accuracy: 0.8491\n",
            "Epoch 1044/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.9110 - val_accuracy: 0.8573\n",
            "Epoch 1045/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0359 - accuracy: 0.9891 - val_loss: 0.9179 - val_accuracy: 0.8573\n",
            "Epoch 1046/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0228 - accuracy: 0.9909 - val_loss: 0.9042 - val_accuracy: 0.8561\n",
            "Epoch 1047/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9761 - val_accuracy: 0.8467\n",
            "Epoch 1048/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.9134 - val_accuracy: 0.8479\n",
            "Epoch 1049/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.9626 - val_accuracy: 0.8467\n",
            "Epoch 1050/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.9224 - val_accuracy: 0.8656\n",
            "Epoch 1051/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.9408 - val_accuracy: 0.8502\n",
            "Epoch 1052/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.9086 - val_accuracy: 0.8479\n",
            "Epoch 1053/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0267 - accuracy: 0.9888 - val_loss: 0.8898 - val_accuracy: 0.8573\n",
            "Epoch 1054/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.9458 - val_accuracy: 0.8514\n",
            "Epoch 1055/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.9237 - val_accuracy: 0.8443\n",
            "Epoch 1056/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.9087 - val_accuracy: 0.8455\n",
            "Epoch 1057/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 0.8595 - val_accuracy: 0.8538\n",
            "Epoch 1058/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.9170 - val_accuracy: 0.8479\n",
            "Epoch 1059/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.8969 - val_accuracy: 0.8573\n",
            "Epoch 1060/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.8316 - val_accuracy: 0.8467\n",
            "Epoch 1061/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.8873 - val_accuracy: 0.8467\n",
            "Epoch 1062/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.8256 - val_accuracy: 0.8514\n",
            "Epoch 1063/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.9002 - val_accuracy: 0.8538\n",
            "Epoch 1064/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.8954 - val_accuracy: 0.8408\n",
            "Epoch 1065/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.8518 - val_accuracy: 0.8597\n",
            "Epoch 1066/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.8634 - val_accuracy: 0.8538\n",
            "Epoch 1067/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.9365 - val_accuracy: 0.8467\n",
            "Epoch 1068/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0412 - accuracy: 0.9858 - val_loss: 0.8811 - val_accuracy: 0.8550\n",
            "Epoch 1069/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 1.0209 - val_accuracy: 0.8349\n",
            "Epoch 1070/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.9222 - val_accuracy: 0.8514\n",
            "Epoch 1071/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.9026 - val_accuracy: 0.8502\n",
            "Epoch 1072/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 1.0863 - val_accuracy: 0.8349\n",
            "Epoch 1073/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.8591 - val_accuracy: 0.8514\n",
            "Epoch 1074/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0261 - accuracy: 0.9897 - val_loss: 0.8863 - val_accuracy: 0.8479\n",
            "Epoch 1075/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.9592 - val_accuracy: 0.8573\n",
            "Epoch 1076/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.9479 - val_accuracy: 0.8526\n",
            "Epoch 1077/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.8758 - val_accuracy: 0.8597\n",
            "Epoch 1078/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 1.0160 - val_accuracy: 0.8479\n",
            "Epoch 1079/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.8840 - val_accuracy: 0.8479\n",
            "Epoch 1080/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.9360 - val_accuracy: 0.8550\n",
            "Epoch 1081/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0220 - accuracy: 0.9917 - val_loss: 0.9162 - val_accuracy: 0.8502\n",
            "Epoch 1082/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.8739 - val_accuracy: 0.8526\n",
            "Epoch 1083/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.9332 - val_accuracy: 0.8502\n",
            "Epoch 1084/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.8649 - val_accuracy: 0.8597\n",
            "Epoch 1085/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0220 - accuracy: 0.9900 - val_loss: 0.8839 - val_accuracy: 0.8597\n",
            "Epoch 1086/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.8809 - val_accuracy: 0.8550\n",
            "Epoch 1087/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 1.0032 - val_accuracy: 0.8443\n",
            "Epoch 1088/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0286 - accuracy: 0.9867 - val_loss: 0.9718 - val_accuracy: 0.8455\n",
            "Epoch 1089/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0257 - accuracy: 0.9900 - val_loss: 0.9329 - val_accuracy: 0.8538\n",
            "Epoch 1090/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 1.0504 - val_accuracy: 0.8455\n",
            "Epoch 1091/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.9354 - val_accuracy: 0.8597\n",
            "Epoch 1092/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.9235 - val_accuracy: 0.8573\n",
            "Epoch 1093/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 1.0229 - val_accuracy: 0.8514\n",
            "Epoch 1094/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.9254 - val_accuracy: 0.8514\n",
            "Epoch 1095/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.9124 - val_accuracy: 0.8491\n",
            "Epoch 1096/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.9905 - val_accuracy: 0.8526\n",
            "Epoch 1097/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 1.0608 - val_accuracy: 0.8432\n",
            "Epoch 1098/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.9906 - val_accuracy: 0.8585\n",
            "Epoch 1099/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 1.0472 - val_accuracy: 0.8420\n",
            "Epoch 1100/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 1.0005 - val_accuracy: 0.8514\n",
            "Epoch 1101/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.9971 - val_accuracy: 0.8561\n",
            "Epoch 1102/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 1.0259 - val_accuracy: 0.8502\n",
            "Epoch 1103/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.9478 - val_accuracy: 0.8573\n",
            "Epoch 1104/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.9526 - val_accuracy: 0.8455\n",
            "Epoch 1105/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.9069 - val_accuracy: 0.8491\n",
            "Epoch 1106/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0303 - accuracy: 0.9891 - val_loss: 1.0294 - val_accuracy: 0.8526\n",
            "Epoch 1107/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.9299 - val_accuracy: 0.8573\n",
            "Epoch 1108/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 1.0266 - val_accuracy: 0.8432\n",
            "Epoch 1109/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.9593 - val_accuracy: 0.8573\n",
            "Epoch 1110/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.9950 - val_accuracy: 0.8573\n",
            "Epoch 1111/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.9789 - val_accuracy: 0.8455\n",
            "Epoch 1112/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 1.0093 - val_accuracy: 0.8550\n",
            "Epoch 1113/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.9865 - val_accuracy: 0.8502\n",
            "Epoch 1114/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0201 - accuracy: 0.9920 - val_loss: 1.0288 - val_accuracy: 0.8455\n",
            "Epoch 1115/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.9446 - val_accuracy: 0.8538\n",
            "Epoch 1116/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 1.0197 - val_accuracy: 0.8432\n",
            "Epoch 1117/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.9587 - val_accuracy: 0.8573\n",
            "Epoch 1118/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.9708 - val_accuracy: 0.8502\n",
            "Epoch 1119/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0274 - accuracy: 0.9906 - val_loss: 0.9827 - val_accuracy: 0.8526\n",
            "Epoch 1120/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.9819 - val_accuracy: 0.8561\n",
            "Epoch 1121/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 1.0234 - val_accuracy: 0.8373\n",
            "Epoch 1122/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 0.9167 - val_accuracy: 0.8491\n",
            "Epoch 1123/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.9829 - val_accuracy: 0.8502\n",
            "Epoch 1124/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.9749 - val_accuracy: 0.8502\n",
            "Epoch 1125/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 1.0106 - val_accuracy: 0.8514\n",
            "Epoch 1126/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.9862 - val_accuracy: 0.8514\n",
            "Epoch 1127/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.9608 - val_accuracy: 0.8491\n",
            "Epoch 1128/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 1.0166 - val_accuracy: 0.8538\n",
            "Epoch 1129/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.0087 - val_accuracy: 0.8420\n",
            "Epoch 1130/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 1.0001 - val_accuracy: 0.8384\n",
            "Epoch 1131/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 1.0015 - val_accuracy: 0.8455\n",
            "Epoch 1132/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 1.0635 - val_accuracy: 0.8432\n",
            "Epoch 1133/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.9928 - val_accuracy: 0.8443\n",
            "Epoch 1134/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.9753 - val_accuracy: 0.8573\n",
            "Epoch 1135/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 1.0103 - val_accuracy: 0.8479\n",
            "Epoch 1136/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 0.9284 - val_accuracy: 0.8632\n",
            "Epoch 1137/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.8931 - val_accuracy: 0.8608\n",
            "Epoch 1138/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.9337 - val_accuracy: 0.8514\n",
            "Epoch 1139/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 1.0607 - val_accuracy: 0.8491\n",
            "Epoch 1140/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.9946 - val_accuracy: 0.8573\n",
            "Epoch 1141/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 1.0010 - val_accuracy: 0.8538\n",
            "Epoch 1142/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.9342 - val_accuracy: 0.8538\n",
            "Epoch 1143/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 1.0288 - val_accuracy: 0.8443\n",
            "Epoch 1144/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0262 - accuracy: 0.9929 - val_loss: 0.9573 - val_accuracy: 0.8443\n",
            "Epoch 1145/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0265 - accuracy: 0.9929 - val_loss: 0.9972 - val_accuracy: 0.8455\n",
            "Epoch 1146/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 1.0150 - val_accuracy: 0.8502\n",
            "Epoch 1147/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.9807 - val_accuracy: 0.8467\n",
            "Epoch 1148/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0380 - accuracy: 0.9915 - val_loss: 0.9470 - val_accuracy: 0.8479\n",
            "Epoch 1149/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 0.9160 - val_accuracy: 0.8514\n",
            "Epoch 1150/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.9967 - val_accuracy: 0.8432\n",
            "Epoch 1151/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0179 - accuracy: 0.9923 - val_loss: 1.0667 - val_accuracy: 0.8432\n",
            "Epoch 1152/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 1.0852 - val_accuracy: 0.8514\n",
            "Epoch 1153/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 1.0383 - val_accuracy: 0.8432\n",
            "Epoch 1154/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 1.0127 - val_accuracy: 0.8514\n",
            "Epoch 1155/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.9998 - val_accuracy: 0.8514\n",
            "Epoch 1156/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 1.0886 - val_accuracy: 0.8491\n",
            "Epoch 1157/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 1.0137 - val_accuracy: 0.8502\n",
            "Epoch 1158/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.9767 - val_accuracy: 0.8526\n",
            "Epoch 1159/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0235 - accuracy: 0.9906 - val_loss: 0.9399 - val_accuracy: 0.8597\n",
            "Epoch 1160/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.9241 - val_accuracy: 0.8561\n",
            "Epoch 1161/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.9879 - val_accuracy: 0.8550\n",
            "Epoch 1162/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.9838 - val_accuracy: 0.8585\n",
            "Epoch 1163/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.9348 - val_accuracy: 0.8561\n",
            "Epoch 1164/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.9561 - val_accuracy: 0.8573\n",
            "Epoch 1165/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0233 - accuracy: 0.9903 - val_loss: 0.9706 - val_accuracy: 0.8550\n",
            "Epoch 1166/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.9537 - val_accuracy: 0.8550\n",
            "Epoch 1167/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.9368 - val_accuracy: 0.8608\n",
            "Epoch 1168/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.9543 - val_accuracy: 0.8514\n",
            "Epoch 1169/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 1.0232 - val_accuracy: 0.8455\n",
            "Epoch 1170/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.9425 - val_accuracy: 0.8502\n",
            "Epoch 1171/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.9491 - val_accuracy: 0.8538\n",
            "Epoch 1172/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 1.0163 - val_accuracy: 0.8632\n",
            "Epoch 1173/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 1.0552 - val_accuracy: 0.8573\n",
            "Epoch 1174/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0280 - accuracy: 0.9894 - val_loss: 0.9482 - val_accuracy: 0.8538\n",
            "Epoch 1175/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0244 - accuracy: 0.9909 - val_loss: 0.9727 - val_accuracy: 0.8491\n",
            "Epoch 1176/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.9555 - val_accuracy: 0.8585\n",
            "Epoch 1177/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.9279 - val_accuracy: 0.8491\n",
            "Epoch 1178/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.9387 - val_accuracy: 0.8514\n",
            "Epoch 1179/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0277 - accuracy: 0.9932 - val_loss: 1.0350 - val_accuracy: 0.8479\n",
            "Epoch 1180/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.9814 - val_accuracy: 0.8491\n",
            "Epoch 1181/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 1.1425 - val_accuracy: 0.8455\n",
            "Epoch 1182/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.9782 - val_accuracy: 0.8561\n",
            "Epoch 1183/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.9901 - val_accuracy: 0.8467\n",
            "Epoch 1184/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0392 - accuracy: 0.9906 - val_loss: 0.9502 - val_accuracy: 0.8597\n",
            "Epoch 1185/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.9413 - val_accuracy: 0.8608\n",
            "Epoch 1186/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.9964 - val_accuracy: 0.8491\n",
            "Epoch 1187/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.9903 - val_accuracy: 0.8561\n",
            "Epoch 1188/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 1.0061 - val_accuracy: 0.8526\n",
            "Epoch 1189/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 1.0020 - val_accuracy: 0.8632\n",
            "Epoch 1190/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.9874 - val_accuracy: 0.8573\n",
            "Epoch 1191/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 1.0312 - val_accuracy: 0.8479\n",
            "Epoch 1192/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 0.9895 - val_accuracy: 0.8455\n",
            "Epoch 1193/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 1.0183 - val_accuracy: 0.8573\n",
            "Epoch 1194/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 1.0362 - val_accuracy: 0.8526\n",
            "Epoch 1195/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0252 - accuracy: 0.9906 - val_loss: 1.0131 - val_accuracy: 0.8608\n",
            "Epoch 1196/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 1.1308 - val_accuracy: 0.8337\n",
            "Epoch 1197/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 1.0469 - val_accuracy: 0.8502\n",
            "Epoch 1198/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 1.0152 - val_accuracy: 0.8479\n",
            "Epoch 1199/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.9953 - val_accuracy: 0.8644\n",
            "Epoch 1200/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0172 - accuracy: 0.9929 - val_loss: 1.0350 - val_accuracy: 0.8573\n",
            "Epoch 1201/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 1.0192 - val_accuracy: 0.8526\n",
            "Epoch 1202/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 1.0480 - val_accuracy: 0.8526\n",
            "Epoch 1203/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 1.0180 - val_accuracy: 0.8561\n",
            "Epoch 1204/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 1.0407 - val_accuracy: 0.8491\n",
            "Epoch 1205/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 1.0440 - val_accuracy: 0.8479\n",
            "Epoch 1206/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 1.0423 - val_accuracy: 0.8443\n",
            "Epoch 1207/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0162 - accuracy: 0.9929 - val_loss: 0.9570 - val_accuracy: 0.8491\n",
            "Epoch 1208/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 1.0145 - val_accuracy: 0.8491\n",
            "Epoch 1209/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 1.0010 - val_accuracy: 0.8514\n",
            "Epoch 1210/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.9816 - val_accuracy: 0.8491\n",
            "Epoch 1211/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.9044 - val_accuracy: 0.8538\n",
            "Epoch 1212/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 1.0480 - val_accuracy: 0.8491\n",
            "Epoch 1213/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 1.0634 - val_accuracy: 0.8561\n",
            "Epoch 1214/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 1.1063 - val_accuracy: 0.8526\n",
            "Epoch 1215/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0213 - accuracy: 0.9900 - val_loss: 0.9775 - val_accuracy: 0.8432\n",
            "Epoch 1216/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 1.0157 - val_accuracy: 0.8479\n",
            "Epoch 1217/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 1.0124 - val_accuracy: 0.8550\n",
            "Epoch 1218/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 1.0236 - val_accuracy: 0.8491\n",
            "Epoch 1219/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 1.0482 - val_accuracy: 0.8502\n",
            "Epoch 1220/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.9897 - val_accuracy: 0.8608\n",
            "Epoch 1221/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 1.0690 - val_accuracy: 0.8561\n",
            "Epoch 1222/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.0389 - val_accuracy: 0.8526\n",
            "Epoch 1223/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.9986 - val_accuracy: 0.8597\n",
            "Epoch 1224/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 1.0886 - val_accuracy: 0.8608\n",
            "Epoch 1225/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 1.0777 - val_accuracy: 0.8620\n",
            "Epoch 1226/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.0310 - val_accuracy: 0.8420\n",
            "Epoch 1227/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 1.0091 - val_accuracy: 0.8573\n",
            "Epoch 1228/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.9798 - val_accuracy: 0.8502\n",
            "Epoch 1229/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0153 - accuracy: 0.9941 - val_loss: 1.0295 - val_accuracy: 0.8620\n",
            "Epoch 1230/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.9600 - val_accuracy: 0.8573\n",
            "Epoch 1231/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 1.0668 - val_accuracy: 0.8573\n",
            "Epoch 1232/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.9604 - val_accuracy: 0.8585\n",
            "Epoch 1233/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 1.1199 - val_accuracy: 0.8526\n",
            "Epoch 1234/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 1.0843 - val_accuracy: 0.8608\n",
            "Epoch 1235/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 1.0357 - val_accuracy: 0.8479\n",
            "Epoch 1236/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 1.0533 - val_accuracy: 0.8502\n",
            "Epoch 1237/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.9897 - val_accuracy: 0.8597\n",
            "Epoch 1238/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0185 - accuracy: 0.9926 - val_loss: 1.0554 - val_accuracy: 0.8550\n",
            "Epoch 1239/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.0635 - val_accuracy: 0.8550\n",
            "Epoch 1240/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 1.0524 - val_accuracy: 0.8585\n",
            "Epoch 1241/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 1.0520 - val_accuracy: 0.8550\n",
            "Epoch 1242/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 1.0295 - val_accuracy: 0.8597\n",
            "Epoch 1243/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 1.0125 - val_accuracy: 0.8620\n",
            "Epoch 1244/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 1.0411 - val_accuracy: 0.8491\n",
            "Epoch 1245/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0146 - accuracy: 0.9938 - val_loss: 1.0418 - val_accuracy: 0.8502\n",
            "Epoch 1246/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 0.9927 - val_accuracy: 0.8573\n",
            "Epoch 1247/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 1.0137 - val_accuracy: 0.8632\n",
            "Epoch 1248/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 1.1195 - val_accuracy: 0.8597\n",
            "Epoch 1249/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.9907 - val_accuracy: 0.8573\n",
            "Epoch 1250/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 1.0345 - val_accuracy: 0.8597\n",
            "Epoch 1251/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.9420 - val_accuracy: 0.8538\n",
            "Epoch 1252/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 1.1261 - val_accuracy: 0.8408\n",
            "Epoch 1253/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 1.0511 - val_accuracy: 0.8514\n",
            "Epoch 1254/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 1.1109 - val_accuracy: 0.8455\n",
            "Epoch 1255/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 1.0707 - val_accuracy: 0.8443\n",
            "Epoch 1256/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 1.0214 - val_accuracy: 0.8538\n",
            "Epoch 1257/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0167 - accuracy: 0.9929 - val_loss: 1.0674 - val_accuracy: 0.8467\n",
            "Epoch 1258/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.9880 - val_accuracy: 0.8561\n",
            "Epoch 1259/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.9821 - val_accuracy: 0.8514\n",
            "Epoch 1260/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0157 - accuracy: 0.9929 - val_loss: 1.0729 - val_accuracy: 0.8632\n",
            "Epoch 1261/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0183 - accuracy: 0.9929 - val_loss: 1.0007 - val_accuracy: 0.8573\n",
            "Epoch 1262/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0237 - accuracy: 0.9912 - val_loss: 1.1124 - val_accuracy: 0.8443\n",
            "Epoch 1263/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0362 - accuracy: 0.9917 - val_loss: 0.9881 - val_accuracy: 0.8538\n",
            "Epoch 1264/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0190 - accuracy: 0.9923 - val_loss: 1.0525 - val_accuracy: 0.8479\n",
            "Epoch 1265/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 1.0849 - val_accuracy: 0.8538\n",
            "Epoch 1266/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 1.0270 - val_accuracy: 0.8644\n",
            "Epoch 1267/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.1627 - val_accuracy: 0.8420\n",
            "Epoch 1268/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.9798 - val_accuracy: 0.8502\n",
            "Epoch 1269/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 1.0973 - val_accuracy: 0.8467\n",
            "Epoch 1270/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 1.1494 - val_accuracy: 0.8443\n",
            "Epoch 1271/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0160 - accuracy: 0.9938 - val_loss: 1.0392 - val_accuracy: 0.8526\n",
            "Epoch 1272/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 1.0313 - val_accuracy: 0.8514\n",
            "Epoch 1273/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 1.0420 - val_accuracy: 0.8526\n",
            "Epoch 1274/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 1.0540 - val_accuracy: 0.8526\n",
            "Epoch 1275/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.9934 - val_accuracy: 0.8632\n",
            "Epoch 1276/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 1.0545 - val_accuracy: 0.8420\n",
            "Epoch 1277/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 1.0149 - val_accuracy: 0.8514\n",
            "Epoch 1278/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 1.1591 - val_accuracy: 0.8491\n",
            "Epoch 1279/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 1.0418 - val_accuracy: 0.8479\n",
            "Epoch 1280/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0196 - accuracy: 0.9923 - val_loss: 1.0408 - val_accuracy: 0.8526\n",
            "Epoch 1281/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 1.1056 - val_accuracy: 0.8455\n",
            "Epoch 1282/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 1.1389 - val_accuracy: 0.8526\n",
            "Epoch 1283/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 1.0179 - val_accuracy: 0.8538\n",
            "Epoch 1284/1300\n",
            "212/212 [==============================] - 3s 12ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 1.1779 - val_accuracy: 0.8373\n",
            "Epoch 1285/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 1.1034 - val_accuracy: 0.8514\n",
            "Epoch 1286/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 1.1178 - val_accuracy: 0.8455\n",
            "Epoch 1287/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0155 - accuracy: 0.9935 - val_loss: 1.0156 - val_accuracy: 0.8443\n",
            "Epoch 1288/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.0935 - val_accuracy: 0.8514\n",
            "Epoch 1289/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 1.1241 - val_accuracy: 0.8420\n",
            "Epoch 1290/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 1.1087 - val_accuracy: 0.8620\n",
            "Epoch 1291/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 1.0658 - val_accuracy: 0.8538\n",
            "Epoch 1292/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.1580 - val_accuracy: 0.8491\n",
            "Epoch 1293/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 1.0647 - val_accuracy: 0.8514\n",
            "Epoch 1294/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 1.1261 - val_accuracy: 0.8408\n",
            "Epoch 1295/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 1.0935 - val_accuracy: 0.8514\n",
            "Epoch 1296/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 1.1030 - val_accuracy: 0.8538\n",
            "Epoch 1297/1300\n",
            "212/212 [==============================] - 3s 13ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 1.0676 - val_accuracy: 0.8455\n",
            "Epoch 1298/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0335 - accuracy: 0.9926 - val_loss: 1.0746 - val_accuracy: 0.8608\n",
            "Epoch 1299/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 1.0120 - val_accuracy: 0.8550\n",
            "Epoch 1300/1300\n",
            "212/212 [==============================] - 3s 14ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 1.0910 - val_accuracy: 0.8479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "dhxs4EQrvhDm",
        "outputId": "a91b7ccb-136d-45b9-f148-7d2c46301c7b"
      },
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUnp10fz01lP",
        "outputId": "70f1f8b7-1531-478f-9728-ae8c39d90436"
      },
      "source": [
        "import os\n",
        "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
        "save_dir = '/content/drive/My Drive/Save_model'\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved trained model at /content/drive/My Drive/Save_model/Emotion_Voice_Detection_Model.h5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3EbPsZn2Eh3"
      },
      "source": [
        "import json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoJv3LLV1S6x",
        "outputId": "710c2a4c-b619-4cc8-800a-d311db1769df"
      },
      "source": [
        "import keras\n",
        "loaded_model = keras.models.load_model('/content/drive/My Drive/Save_model/Emotion_Voice_Detection_Model.h5')\n",
        "loaded_model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           768       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 5, 128)            82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1, 128)            82048     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1, 128)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 1032      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165,896\n",
            "Trainable params: 165,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}