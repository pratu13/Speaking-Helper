{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugARdLgg8jrh",
    "outputId": "bf7a142d-917d-4522-84eb-48bbd1e66ed5"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import librosa\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iSzgl7s-srf",
    "outputId": "ba277da4-8049-4885-addc-d15b0bd71e0b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAZzXc2i8vPZ",
    "outputId": "fad4b708-6cb1-4b26-d86e-38448e849fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 40, 128)           768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 40, 128)           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 128)            82048     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 128)            82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 1032      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,896\n",
      "Trainable params: 165,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Prediction is   neutral\n",
      "Prediction is   angry\n",
      "Sentiment analysis for live audio:\n",
      "Prediction is   disgust\n"
     ]
    }
   ],
   "source": [
    "class LivePredictions:\n",
    "    \"\"\"\n",
    "    Main class of the application.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file):\n",
    "        \"\"\"\n",
    "        Init method is used to initialize the main parameters.\n",
    "        \"\"\"\n",
    "        self.file = file\n",
    "        MODEL_DIR_PATH ='AudioData/Save_model/'\n",
    "        self.path = MODEL_DIR_PATH + 'Emotion_Voice_Detection_Model.h5'\n",
    "        self.loaded_model = keras.models.load_model(self.path)\n",
    "    def make_predictions(self):\n",
    "        \"\"\"\n",
    "        Method to process the files and create your features.\n",
    "        \"\"\"\n",
    "        data, sampling_rate = librosa.load(self.file)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "        x = np.expand_dims(mfccs, axis=1)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #predictions = self.loaded_model.predict_classes(x)\n",
    "        predict_x=self.loaded_model.predict(x) \n",
    "        classes_x=np.argmax(predict_x,axis=1)\n",
    "        print( \"Prediction is\", \" \", self.convert_class_to_emotion(classes_x))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_class_to_emotion(pred):\n",
    "        \"\"\"\n",
    "        Method to convert the predictions (int) into human readable strings.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_conversion = {'0': 'neutral',\n",
    "                            '1': 'calm',\n",
    "                            '2': 'happy',\n",
    "                            '3': 'sad',\n",
    "                            '4': 'angry',\n",
    "                            '5': 'fearful',\n",
    "                            '6': 'disgust',\n",
    "                            '7': 'surprised'}\n",
    "\n",
    "        for key, value in label_conversion.items():\n",
    "            if int(key) == pred:\n",
    "                label = value\n",
    "        return label\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    EXAMPLES_PATH = 'AudioData/examples/'\n",
    "    live_prediction = LivePredictions(file=EXAMPLES_PATH + 'Neutral.wav')\n",
    "    live_prediction.loaded_model.summary()\n",
    "    live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + 'Angry.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + '10-16-07-29-82-30-63.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + '03-01-05-02-02-02-01.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    live_prediction = LivePredictions(file=EXAMPLES_PATH + '03-01-05-02-01-01-01.wav')\n",
    "    live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + '03-01-08-01-02-02-01.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + 'i-cant-take-this.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    #live_prediction = LivePredictions(file=EXAMPLES_PATH + 'that-feels-really-powerful.wav')\n",
    "    #live_prediction.make_predictions()\n",
    "    print(\"Sentiment analysis for live audio:\")\n",
    "    live_prediction = LivePredictions(file=EXAMPLES_PATH + 'liveaudio.wav')\n",
    "    live_prediction.make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIel5KaQIxjr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LiveAudio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
